{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ddfb01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yfinance\n",
      "  Downloading yfinance-0.2.66-py2.py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: pandas>=1.3.0 in /Users/paulgrass/anaconda3/envs/mech-coding/lib/python3.12/site-packages (from yfinance) (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /Users/paulgrass/anaconda3/envs/mech-coding/lib/python3.12/site-packages (from yfinance) (2.3.4)\n",
      "Collecting requests>=2.31 (from yfinance)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting multitasking>=0.0.7 (from yfinance)\n",
      "  Downloading multitasking-0.0.12.tar.gz (19 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: platformdirs>=2.0.0 in /Users/paulgrass/anaconda3/envs/mech-coding/lib/python3.12/site-packages (from yfinance) (4.5.0)\n",
      "Requirement already satisfied: pytz>=2022.5 in /Users/paulgrass/anaconda3/envs/mech-coding/lib/python3.12/site-packages (from yfinance) (2025.2)\n",
      "Collecting frozendict>=2.3.4 (from yfinance)\n",
      "  Downloading frozendict-2.4.7-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting peewee>=3.16.2 (from yfinance)\n",
      "  Downloading peewee-3.18.3.tar.gz (3.0 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting beautifulsoup4>=4.11.1 (from yfinance)\n",
      "  Downloading beautifulsoup4-4.14.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting curl_cffi>=0.7 (from yfinance)\n",
      "  Downloading curl_cffi-0.13.0-cp39-abi3-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting protobuf>=3.19.0 (from yfinance)\n",
      "  Downloading protobuf-6.33.1-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
      "Collecting websockets>=13.0 (from yfinance)\n",
      "  Downloading websockets-15.0.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4>=4.11.1->yfinance)\n",
      "  Downloading soupsieve-2.8-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/paulgrass/anaconda3/envs/mech-coding/lib/python3.12/site-packages (from beautifulsoup4>=4.11.1->yfinance) (4.15.0)\n",
      "Collecting cffi>=1.12.0 (from curl_cffi>=0.7->yfinance)\n",
      "  Downloading cffi-2.0.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: certifi>=2024.2.2 in /Users/paulgrass/anaconda3/envs/mech-coding/lib/python3.12/site-packages (from curl_cffi>=0.7->yfinance) (2025.11.12)\n",
      "Collecting pycparser (from cffi>=1.12.0->curl_cffi>=0.7->yfinance)\n",
      "  Downloading pycparser-2.23-py3-none-any.whl.metadata (993 bytes)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/paulgrass/anaconda3/envs/mech-coding/lib/python3.12/site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/paulgrass/anaconda3/envs/mech-coding/lib/python3.12/site-packages (from pandas>=1.3.0->yfinance) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/paulgrass/anaconda3/envs/mech-coding/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.31->yfinance)\n",
      "  Downloading charset_normalizer-3.4.4-cp312-cp312-macosx_10_13_universal2.whl.metadata (37 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/paulgrass/anaconda3/envs/mech-coding/lib/python3.12/site-packages (from requests>=2.31->yfinance) (3.11)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.31->yfinance)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Downloading yfinance-0.2.66-py2.py3-none-any.whl (123 kB)\n",
      "Downloading beautifulsoup4-4.14.2-py3-none-any.whl (106 kB)\n",
      "Downloading curl_cffi-0.13.0-cp39-abi3-macosx_11_0_arm64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cffi-2.0.0-cp312-cp312-macosx_11_0_arm64.whl (181 kB)\n",
      "Downloading frozendict-2.4.7-py3-none-any.whl (16 kB)\n",
      "Downloading protobuf-6.33.1-cp39-abi3-macosx_10_9_universal2.whl (427 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp312-cp312-macosx_10_13_universal2.whl (208 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading soupsieve-2.8-py3-none-any.whl (36 kB)\n",
      "Downloading websockets-15.0.1-cp312-cp312-macosx_11_0_arm64.whl (173 kB)\n",
      "Downloading pycparser-2.23-py3-none-any.whl (118 kB)\n",
      "Building wheels for collected packages: multitasking, peewee\n",
      "  Building wheel for multitasking (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for multitasking: filename=multitasking-0.0.12-py3-none-any.whl size=15636 sha256=1ac16c789448cc6b830926e0926f3a047a37238b053769a361626a880870e506\n",
      "  Stored in directory: /Users/paulgrass/Library/Caches/pip/wheels/cc/bd/6f/664d62c99327abeef7d86489e6631cbf45b56fbf7ef1d6ef00\n",
      "  Building wheel for peewee (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for peewee: filename=peewee-3.18.3-cp312-cp312-macosx_11_0_arm64.whl size=267774 sha256=f2b00190a6d5373c382232f5ea18b7203ce11bc6ea5e49e355ac2f16e4f67062\n",
      "  Stored in directory: /Users/paulgrass/Library/Caches/pip/wheels/e2/48/b6/675a31c56e50b8b343e1ffbb1d9209f0d95025e2cfa0bbeeed\n",
      "Successfully built multitasking peewee\n",
      "Installing collected packages: peewee, multitasking, websockets, urllib3, soupsieve, pycparser, protobuf, frozendict, charset_normalizer, requests, cffi, beautifulsoup4, curl_cffi, yfinance\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m14/14\u001b[0m [yfinance]/14\u001b[0m [curl_cffi]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed beautifulsoup4-4.14.2 cffi-2.0.0 charset_normalizer-3.4.4 curl_cffi-0.13.0 frozendict-2.4.7 multitasking-0.0.12 peewee-3.18.3 protobuf-6.33.1 pycparser-2.23 requests-2.32.5 soupsieve-2.8 urllib3-2.5.0 websockets-15.0.1 yfinance-0.2.66\n"
     ]
    }
   ],
   "source": [
    "!pip install yfinance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0adb35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run dir: /Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Programming/Git/pilot3-asset-data/d2/runs/run_2025-12-13\n",
      "Current dir: /Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Programming/Git/pilot3-asset-data/d2/current_fx\n",
      "Fetching FX data for USDEUR=X...\n",
      "  ‚úî wrote usdeur_365d.json (258 pts)\n",
      "Fetching FX data for USDGBP=X...\n",
      "  ‚úî wrote usdgbp_365d.json (258 pts)\n",
      "Fetching FX data for USDJPY=X...\n",
      "  ‚úî wrote usdjpy_365d.json (258 pts)\n",
      "Fetching FX data for USDNZD=X...\n",
      "  ‚úî wrote usdnzd_365d.json (258 pts)\n",
      "Fetching FX data for USDMXN=X...\n",
      "  ‚úî wrote usdmxn_365d.json (258 pts)\n",
      "Fetching FX data for USDCNY=X...\n",
      "  ‚úî wrote usdcny_365d.json (258 pts)\n",
      "[main 1b72306] FX data update: 2025-12-13 13:27:52\n",
      " 16 files changed, 12574 insertions(+)\n",
      " create mode 100644 d2/current_fx/fundamentals.json\n",
      " create mode 100644 d2/current_fx/summary.json\n",
      " create mode 100644 d2/current_fx/usdcny_365d.json\n",
      " create mode 100644 d2/current_fx/usdeur_365d.json\n",
      " create mode 100644 d2/current_fx/usdgbp_365d.json\n",
      " create mode 100644 d2/current_fx/usdjpy_365d.json\n",
      " create mode 100644 d2/current_fx/usdmxn_365d.json\n",
      " create mode 100644 d2/current_fx/usdnzd_365d.json\n",
      " create mode 100644 d2/runs/run_2025-12-13/fundamentals.json\n",
      " create mode 100644 d2/runs/run_2025-12-13/summary.json\n",
      " create mode 100644 d2/runs/run_2025-12-13/usdcny_365d.json\n",
      " create mode 100644 d2/runs/run_2025-12-13/usdeur_365d.json\n",
      " create mode 100644 d2/runs/run_2025-12-13/usdgbp_365d.json\n",
      " create mode 100644 d2/runs/run_2025-12-13/usdjpy_365d.json\n",
      " create mode 100644 d2/runs/run_2025-12-13/usdmxn_365d.json\n",
      " create mode 100644 d2/runs/run_2025-12-13/usdnzd_365d.json\n",
      "Pushed to GitHub.\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To github.com:pagrass/pilot1-asset-data.git\n",
      "   93cf2e9..1b72306  main -> main\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import yfinance as yf\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import subprocess\n",
    "\n",
    "# ---------------------------- CONFIG ----------------------------\n",
    "\n",
    "CURRENCIES = {\n",
    "    \"USDEUR=X\": \"Euro Area\",\n",
    "    \"USDGBP=X\": \"United Kingdom\",\n",
    "    \"USDJPY=X\": \"Japan\",\n",
    "    \"USDNZD=X\": \"New Zealand\",\n",
    "    \"USDMXN=X\": \"Mexico\",\n",
    "    \"USDCNY=X\": \"China\",\n",
    "}\n",
    "\n",
    "# Big Mac GDP-adjusted PPP misalignment (in %)\n",
    "PPP_MISALIGN = {\n",
    "    \"USDEUR=X\": 15.2,\n",
    "    \"USDGBP=X\": 13.5,\n",
    "    \"USDJPY=X\": -46.3,\n",
    "    \"USDNZD=X\": -14.8,\n",
    "    \"USDMXN=X\": -12.2,\n",
    "    \"USDCNY=X\": -40.9,\n",
    "}\n",
    "\n",
    "# Big Mac GDP-adjusted PPP misalignment (in %)\n",
    "NAME = {\n",
    "    \"USDEUR=X\": \"Euro\",\n",
    "    \"USDGBP=X\": \"Pound sterling\",\n",
    "    \"USDJPY=X\": \"Japanese yen\",\n",
    "    \"USDNZD=X\": \"New Zealand dollar\",\n",
    "    \"USDMXN=X\": \"Mexican peso\",\n",
    "    \"USDCNY=X\": \"Chinese yuan\",\n",
    "\n",
    "}\n",
    "\n",
    "END = datetime.now()\n",
    "START = END - timedelta(days=365)\n",
    "\n",
    "DEFAULT_BASE_DIR = \"/Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Programming/Git/pilot3-asset-data/d2\"\n",
    "\n",
    "SLEEP_BETWEEN = 8\n",
    "MAX_RETRIES = 3\n",
    "RETRY_DELAY = 4\n",
    "\n",
    "FORBIDDEN_SUBSTRINGS = [\"pilot2-asset-data\"]\n",
    "\n",
    "\n",
    "# ---------------------------- HELPERS ----------------------------\n",
    "\n",
    "def guard_path(path):\n",
    "    norm = os.path.normpath(path)\n",
    "    for bad in FORBIDDEN_SUBSTRINGS:\n",
    "        if bad in norm:\n",
    "            raise RuntimeError(f\"Refusing to write into forbidden path: {norm}\")\n",
    "\n",
    "def safe_mkdirs(path):\n",
    "    guard_path(path)\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "def make_daily_dir(base):\n",
    "    d = os.path.join(base, \"runs\", f\"run_{datetime.now().strftime('%Y-%m-%d')}\")\n",
    "    safe_mkdirs(d)\n",
    "    return d\n",
    "\n",
    "def ensure_current(base):\n",
    "    cur = os.path.join(base, \"current_fx\")\n",
    "    safe_mkdirs(cur)\n",
    "    return cur\n",
    "\n",
    "def write_json(path, obj):\n",
    "    guard_path(path)\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(obj, f, indent=2)\n",
    "\n",
    "def copy_to_current(src, current):\n",
    "    guard_path(current)\n",
    "    dst = os.path.join(current, os.path.basename(src))\n",
    "    with open(src, \"rb\") as s, open(dst, \"wb\") as d:\n",
    "        d.write(s.read())\n",
    "    return dst\n",
    "\n",
    "def git_commit_and_push(repo_root, run_dir, current_dir, branch=\"main\"):\n",
    "    cwd = os.getcwd()\n",
    "    os.chdir(repo_root)\n",
    "    try:\n",
    "        diff = subprocess.run([\"git\", \"status\", \"--porcelain\", current_dir, run_dir],\n",
    "                              capture_output=True, text=True)\n",
    "        if diff.stdout.strip() == \"\":\n",
    "            print(\"No changes to commit.\")\n",
    "            return\n",
    "\n",
    "        subprocess.run([\"git\", \"add\", current_dir, run_dir], check=True)\n",
    "        msg = f\"FX data update: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "        subprocess.run([\"git\", \"commit\", \"-m\", msg], check=True)\n",
    "        subprocess.run([\"git\", \"push\", \"origin\", branch], check=True)\n",
    "        print(\"Pushed to GitHub.\")\n",
    "    finally:\n",
    "        os.chdir(cwd)\n",
    "\n",
    "\n",
    "# ---------------------------- MAIN ----------------------------\n",
    "\n",
    "def main():\n",
    "    base = os.getenv(\"DATA_BASE_DIR\", DEFAULT_BASE_DIR)\n",
    "    guard_path(base)\n",
    "    safe_mkdirs(base)\n",
    "\n",
    "    run_dir = make_daily_dir(base)\n",
    "    current = ensure_current(base)\n",
    "\n",
    "    print(f\"Run dir: {run_dir}\")\n",
    "    print(f\"Current dir: {current}\")\n",
    "\n",
    "    summary = {\n",
    "        \"started_at\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "        \"window_start\": START.strftime(\"%Y-%m-%d\"),\n",
    "        \"window_end\": END.strftime(\"%Y-%m-%d\"),\n",
    "        \"files\": [],\n",
    "        \"errors\": [],\n",
    "    }\n",
    "\n",
    "    # ------------------ FX PRICE DATA ------------------\n",
    "    # ------------------ FX PRICE DATA ------------------\n",
    "    fx_data = {}\n",
    "\n",
    "    for ticker, country in CURRENCIES.items():\n",
    "        print(f\"Fetching FX data for {ticker}...\")\n",
    "\n",
    "        err = None\n",
    "        for attempt in range(1, MAX_RETRIES + 1):\n",
    "            try:\n",
    "                df = yf.Ticker(ticker).history(\n",
    "                    start=START.strftime(\"%Y-%m-%d\"),\n",
    "                    end=END.strftime(\"%Y-%m-%d\"),\n",
    "                    auto_adjust=True,\n",
    "                )\n",
    "                if df.empty:\n",
    "                    raise ValueError(\"Empty history returned\")\n",
    "\n",
    "                prices = [\n",
    "                    [int(ts.timestamp() * 1000), round(float(row[\"Close\"]), 5)]\n",
    "                    for ts, row in df.iterrows()\n",
    "                ]\n",
    "\n",
    "                if not prices:\n",
    "                    raise ValueError(\"No valid prices\")\n",
    "\n",
    "                short = ticker.replace(\"=X\", \"\").replace(\"/\", \"\").lower()\n",
    "                out_path = os.path.join(run_dir, f\"{short}_365d.json\")\n",
    "\n",
    "                write_json(out_path, {\"prices\": prices})\n",
    "                copy_to_current(out_path, current)\n",
    "\n",
    "                fx_data[ticker] = {\n",
    "                    \"country\": country,\n",
    "                    \"name\": NAME[ticker],                 # <-- added\n",
    "                    \"ppp_misalign_percent\": PPP_MISALIGN[ticker],\n",
    "                }\n",
    "\n",
    "                summary[\"files\"].append({\n",
    "                    \"ticker\": ticker,\n",
    "                    \"file\": out_path,\n",
    "                    \"points\": len(prices),\n",
    "                })\n",
    "\n",
    "                print(f\"  ‚úî wrote {short}_365d.json ({len(prices)} pts)\")\n",
    "                err = None\n",
    "                break\n",
    "\n",
    "            except Exception as e:\n",
    "                err = str(e)\n",
    "                print(f\"  ‚ö† attempt {attempt}: {err}\")\n",
    "                time.sleep(RETRY_DELAY)\n",
    "\n",
    "        if err:\n",
    "            summary[\"errors\"].append({\"ticker\": ticker, \"error\": err})\n",
    "\n",
    "        time.sleep(SLEEP_BETWEEN)\n",
    "\n",
    "    # ------------------ FUNDAMENTALS ------------------\n",
    "    fundamentals_path = os.path.join(run_dir, \"fundamentals.json\")\n",
    "    fundamentals_cur = os.path.join(current, \"fundamentals.json\")\n",
    "\n",
    "    write_json(fundamentals_path, fx_data)\n",
    "    write_json(fundamentals_cur, fx_data)\n",
    "\n",
    "    summary[\"fundamentals_file\"] = fundamentals_cur\n",
    "    summary_path = os.path.join(run_dir, \"summary.json\")\n",
    "    write_json(summary_path, summary)\n",
    "    write_json(os.path.join(current, \"summary.json\"), summary)\n",
    "\n",
    "    # Git commit\n",
    "    git_commit_and_push(base, run_dir, current)\n",
    "\n",
    "    print(\"Done.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "603bed1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Daily archive folder: /Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Programming/Git/pilot3-asset-data/main/cryptos/runs/run_2025-12-18\n",
      "üìÇ Current folder for Qualtrics: /Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Programming/Git/pilot3-asset-data/main/cryptos/current\n",
      "‚è≥ Fetching 365-day data for BTC-USD‚Ä¶\n",
      " ‚úÖ Wrote btc_365d.json (365 points)\n",
      "‚è≥ Fetching 365-day data for XMR-USD‚Ä¶\n",
      " ‚úÖ Wrote xmr_365d.json (365 points)\n",
      "‚è≥ Fetching 365-day data for BNB-USD‚Ä¶\n",
      " ‚úÖ Wrote bnb_365d.json (365 points)\n",
      "‚è≥ Fetching 365-day data for BCH-USD‚Ä¶\n",
      " ‚úÖ Wrote bch_365d.json (365 points)\n",
      "‚è≥ Fetching 365-day data for ETH-USD‚Ä¶\n",
      " ‚úÖ Wrote eth_365d.json (365 points)\n",
      "‚è≥ Fetching 365-day data for TRX-USD‚Ä¶\n",
      " ‚úÖ Wrote trx_365d.json (365 points)\n",
      "Has MSFT exact?: True\n",
      "MSFT-like keys: ['MSFT']\n",
      "‚úÖ Pushed to origin; GitHub Action will purge jsDelivr cache.\n",
      "üèÅ Done.\n",
      "All symbols fetched successfully.\n",
      "Latest 'current' folder ready for Qualtrics: /Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Programming/Git/pilot3-asset-data/main/cryptos/current\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To github.com:pagrass/pilot1-asset-data.git\n",
      "   60e1150..dd69c46  main -> main\n"
     ]
    }
   ],
   "source": [
    "#Code Cryptos\n",
    "\n",
    "import csv\n",
    "import subprocess\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Deps: pip install yfinance\n",
    "import yfinance as yf\n",
    "\n",
    "# -------------------- Config --------------------\n",
    "\n",
    "#STOCKS  = [\"CSCO\", \"MSFT\", \"TER\", \"AKAM\", \"NTAP\", \"AMKR\"]\n",
    "\n",
    "#Replication cryptos\n",
    "\n",
    "\n",
    "#CRYPTOS = [\"BCH-USD\", \"ETH-USD\", \"XMR-USD\"] \n",
    "\n",
    "#Own predictions cryptos\n",
    "#CRYPTOS = [\"XRP-USD\", \"BNB-USD\", \"BTC-USD\"]\n",
    "\n",
    "#All cryptos\n",
    "CRYPTOS = [\"BTC-USD\", \"XMR-USD\", \"BNB-USD\", \"BCH-USD\", \"ETH-USD\", \"TRX-USD\"]\n",
    "\n",
    "TICKERS = CRYPTOS\n",
    "#+ CRYPTOS\n",
    "\n",
    "FUND_TICKERS = [\"CSCO\", \"MSFT\", \"TER\", \"AKAM\", \"NTAP\", \"AMKR\"]\n",
    "\n",
    "SECTOR_MAP = {\n",
    "    \"CSCO\": \"Information Technology\",\n",
    "    \"MSFT\": \"Information Technology\",\n",
    "    \"TER\": \"Information Technology\",\n",
    "    \"AKAM\": \"Information Technology\",\n",
    "    \"NTAP\":  \"Information Technology\",\n",
    "    \"AMKR\":   \"Information Technology\",\n",
    "}\n",
    "\n",
    "# Date window\n",
    "END   = datetime.now()\n",
    "START = END - timedelta(days=365)\n",
    "\n",
    "# Default base dir (each run gets a new subfolder here)\n",
    "DEFAULT_BASE_DIR = \"/Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Programming/Git/pilot3-asset-data/main/cryptos\"\n",
    "\n",
    "# Path to CSV ‚Äúdictionary‚Äù\n",
    "CSV_METRICS_PATH = \"/Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Model Spillovers/Data/Stock Selection/preselection/candidate_subset_all.csv\"\n",
    "\n",
    "# Rate limiting\n",
    "SLEEP_BETWEEN_TICKERS_SEC = 10\n",
    "MAX_RETRIES = 3\n",
    "RETRY_DELAY_SEC = 5\n",
    "\n",
    "# Safety: never allow writing into these substrings\n",
    "FORBIDDEN_SUBSTRINGS = [\"pilot2-asset-data\"]\n",
    "\n",
    "# -------------------- Helpers --------------------\n",
    "\n",
    "def git_commit_and_push(repo_root: str, run_dir: str, current_dir: str, branch: str = \"main\"):\n",
    "    # Only commit if there are changes in current/ or today's run folder\n",
    "    rel_run = os.path.relpath(run_dir, repo_root)\n",
    "    rel_cur = os.path.relpath(current_dir, repo_root)\n",
    "\n",
    "    cwd_before = os.getcwd()\n",
    "    os.chdir(repo_root)\n",
    "    try:\n",
    "        diff = subprocess.run(\n",
    "            [\"git\", \"status\", \"--porcelain\", rel_cur, rel_run],\n",
    "            capture_output=True, text=True\n",
    "        )\n",
    "        if diff.returncode != 0:\n",
    "            print(\"‚ö†Ô∏è  git status failed; not pushing.\")\n",
    "            return\n",
    "        if diff.stdout.strip() == \"\":\n",
    "            print(\"‚ÑπÔ∏è  No changes to commit; skipping push.\")\n",
    "            return\n",
    "\n",
    "        # Stage just what we care about\n",
    "        subprocess.run([\"git\", \"add\", rel_cur, rel_run], check=True)\n",
    "\n",
    "        # Commit\n",
    "        msg = f\"Update data: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "        commit = subprocess.run([\"git\", \"commit\", \"-m\", msg], capture_output=True, text=True)\n",
    "        if commit.returncode != 0:\n",
    "            print(commit.stdout or commit.stderr or \"‚ÑπÔ∏è  Nothing to commit.\")\n",
    "            return\n",
    "\n",
    "        # Push\n",
    "        subprocess.run([\"git\", \"push\", \"origin\", branch], check=True)\n",
    "        print(\"‚úÖ Pushed to origin; GitHub Action will purge jsDelivr cache.\")\n",
    "    finally:\n",
    "        os.chdir(cwd_before)\n",
    "\n",
    "def guard_path(path: str):\n",
    "    norm = os.path.normpath(path)\n",
    "    for bad in FORBIDDEN_SUBSTRINGS:\n",
    "        if bad in norm:\n",
    "            raise RuntimeError(f\"Refusing to write into forbidden path: {norm}\")\n",
    "\n",
    "def safe_mkdirs(path: str):\n",
    "    guard_path(path)\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "def make_daily_run_dir(base_dir: str) -> str:\n",
    "    date_str = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    run_dir = os.path.join(base_dir, \"runs\", f\"run_{date_str}\")\n",
    "    safe_mkdirs(run_dir)\n",
    "    return run_dir\n",
    "\n",
    "def ensure_current_dir(base_dir: str) -> str:\n",
    "    cur = os.path.join(base_dir, \"current\")\n",
    "    safe_mkdirs(cur)\n",
    "    return cur\n",
    "\n",
    "def copy_to_current(src_path: str, current_dir: str):\n",
    "    guard_path(current_dir)\n",
    "    dst_path = os.path.join(current_dir, os.path.basename(src_path))\n",
    "    with open(src_path, \"rb\") as s, open(dst_path, \"wb\") as d:\n",
    "        d.write(s.read())\n",
    "    return dst_path\n",
    "\n",
    "def write_json(path: str, obj):\n",
    "    guard_path(path)\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(obj, f, indent=2)\n",
    "\n",
    "# ---------- CSV metrics ----------\n",
    "\n",
    "def _coerce_number(val):\n",
    "    \"\"\"Coerce CSV field to float if possible; return None for empty/invalid.\"\"\"\n",
    "    if val is None:\n",
    "        return None\n",
    "    s = str(val).strip()\n",
    "    if s == \"\" or s.lower() in {\"na\", \"nan\", \"none\"}:\n",
    "        return None\n",
    "    try:\n",
    "        return float(s.replace(\",\", \"\"))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def fetch_metrics_from_csv(symbols, csv_path, sector_map=None):\n",
    "    \"\"\"\n",
    "    Pull marketcap, pb_current, pb_current_pctile, div_y from a CSV keyed by ticker.\n",
    "\n",
    "    Post-processing:\n",
    "      - marketcap -> divide by 1,000,000 and round to 2 decimals (millions)\n",
    "      - pb_current_pctile -> round to 2 decimals\n",
    "      - div_y (aka div_yield/dividend_yield) -> divide by 100 (to decimal)\n",
    "      - valuation (new): Low / Mid / High based on pb_current_pctile\n",
    "    \"\"\"\n",
    "    lookup = {}\n",
    "    with open(csv_path, newline=\"\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            row_lower = {k.lower(): v for k, v in row.items()}\n",
    "            tk = (row_lower.get(\"ticker\") or row_lower.get(\"symbol\") or \"\").strip().upper()\n",
    "            if tk:\n",
    "                lookup[tk] = row_lower\n",
    "\n",
    "    print(\"Has MSFT exact?:\", \"MSFT\" in lookup)\n",
    "\n",
    "    # show any keys that \"contain\" MSFT (suffixes, weird formats)\n",
    "    msft_like = [k for k in lookup.keys() if \"MSFT\" in k]\n",
    "    print(\"MSFT-like keys:\", msft_like[:50])\n",
    "    out = {}\n",
    "    for sym in symbols:\n",
    "        key = sym.upper()\n",
    "        row = lookup.get(key)\n",
    "        if not row:\n",
    "            out[key] = {\"error\": \"Ticker not found in CSV\", \"sector\": (sector_map or {}).get(key)}\n",
    "            continue\n",
    "\n",
    "        mc_raw = _coerce_number(row.get(\"marketcap\"))\n",
    "        pb = _coerce_number(row.get(\"pb_current\"))\n",
    "        pb_pct_raw = _coerce_number(row.get(\"pb_current_pctile\"))\n",
    "\n",
    "        # Flexible dividend yield column handling\n",
    "        div_candidates = [\"div_y\", \"div_yield\", \"dividend_yield\"]\n",
    "        div_raw = None\n",
    "        for c in div_candidates:\n",
    "            if c in row:\n",
    "                div_raw = _coerce_number(row.get(c))\n",
    "                if div_raw is not None:\n",
    "                    break\n",
    "\n",
    "        # ---- Post-processing transforms ----\n",
    "        mc_millions = round(mc_raw / 1_000_000, 2) if mc_raw is not None else None\n",
    "        pb_pct = round(pb_pct_raw * 100, 0) if pb_pct_raw is not None else None\n",
    "        div_val = (div_raw) if div_raw is not None else None\n",
    "\n",
    "        # ---- Valuation classification ----\n",
    "        if pb_pct is None:\n",
    "            valuation = None\n",
    "        elif pb_pct <= 30:\n",
    "            valuation = \"Low\"\n",
    "        elif pb_pct >= 70:\n",
    "            valuation = \"High\"\n",
    "        else:\n",
    "            valuation = \"Mid\"\n",
    "\n",
    "        out[key] = {\n",
    "            \"marketcap\": mc_millions,\n",
    "            \"pb_current\": pb,\n",
    "            \"pb_current_pctile\": pb_pct,\n",
    "            \"div_y\": div_val,\n",
    "            \"valuation\": valuation,   # üëà new field\n",
    "        }\n",
    "        if sector_map:\n",
    "            out[key][\"sector\"] = sector_map.get(key)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# -------------------- Main --------------------\n",
    "\n",
    "def main():\n",
    "    base_dir = os.getenv(\"DATA_BASE_DIR\", DEFAULT_BASE_DIR)\n",
    "    guard_path(base_dir)\n",
    "    safe_mkdirs(base_dir)\n",
    "\n",
    "    run_dir = make_daily_run_dir(base_dir)\n",
    "    current_dir = ensure_current_dir(base_dir)\n",
    "\n",
    "    print(f\"üìÅ Daily archive folder: {run_dir}\")\n",
    "    print(f\"üìÇ Current folder for Qualtrics: {current_dir}\")\n",
    "\n",
    "    run_summary = {\n",
    "        \"started_at\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "        \"window_start\": START.strftime(\"%Y-%m-%d\"),\n",
    "        \"window_end\": END.strftime(\"%Y-%m-%d\"),\n",
    "        \"files\": [],\n",
    "        \"errors\": [],\n",
    "    }\n",
    "\n",
    "    # ---- Price history (yfinance) ----\n",
    "    for sym in TICKERS:\n",
    "        print(f\"‚è≥ Fetching 365-day data for {sym}‚Ä¶\")\n",
    "        last_err = None\n",
    "        for attempt in range(1, MAX_RETRIES + 1):\n",
    "            try:\n",
    "                tkr = yf.Ticker(sym)\n",
    "                df = tkr.history(\n",
    "                    start=START.strftime(\"%Y-%m-%d\"),\n",
    "                    end=END.strftime(\"%Y-%m-%d\"),\n",
    "                    auto_adjust=True,\n",
    "                )\n",
    "                if df is None or df.empty:\n",
    "                    raise ValueError(\"Empty dataframe returned.\")\n",
    "\n",
    "                pts = [\n",
    "                    [int(row_ts.timestamp() * 1000), round(float(row[\"Close\"]), 2)]\n",
    "                    for row_ts, row in df.iterrows()\n",
    "                    if row.get(\"Close\") is not None\n",
    "                ]\n",
    "                if not pts:\n",
    "                    raise ValueError(\"No valid close prices found.\")\n",
    "\n",
    "                out_sym = sym.replace(\"-USD\", \"\").replace(\".\", \"\").lower()\n",
    "\n",
    "                out_path = os.path.join(run_dir, f\"{out_sym}_365d.json\")\n",
    "                write_json(out_path, {\"prices\": pts})\n",
    "\n",
    "                copy_to_current(out_path, current_dir)\n",
    "\n",
    "                print(f\" ‚úÖ Wrote {out_sym}_365d.json ({len(pts)} points)\")\n",
    "\n",
    "                run_summary[\"files\"].append({\n",
    "                    \"symbol\": sym,\n",
    "                    \"file\": out_path,\n",
    "                    \"points\": len(pts),\n",
    "                    \"first_ts\": pts[0][0],\n",
    "                    \"last_ts\": pts[-1][0],\n",
    "                })\n",
    "                last_err = None\n",
    "                break\n",
    "            except Exception as e:\n",
    "                last_err = str(e)\n",
    "                print(f\"   ‚ö†Ô∏è Attempt {attempt}/{MAX_RETRIES} failed: {last_err}\")\n",
    "                if attempt < MAX_RETRIES:\n",
    "                    time.sleep(RETRY_DELAY_SEC)\n",
    "\n",
    "        if last_err:\n",
    "            run_summary[\"errors\"].append({\"symbol\": sym, \"error\": last_err})\n",
    "\n",
    "        time.sleep(SLEEP_BETWEEN_TICKERS_SEC)\n",
    "\n",
    "    # ---- Metrics from CSV (no Yahoo fundamentals) ----\n",
    "    try:\n",
    "        funds = fetch_metrics_from_csv(\n",
    "            FUND_TICKERS,\n",
    "            CSV_METRICS_PATH,\n",
    "            sector_map=SECTOR_MAP\n",
    "        )\n",
    "    except Exception as e:\n",
    "        funds = {sym: {\"error\": f\"CSV read failed: {e}\", \"sector\": SECTOR_MAP.get(sym)} for sym in FUND_TICKERS}\n",
    "\n",
    "    funds_run_path = os.path.join(run_dir, \"fundamentals.json\")\n",
    "    funds_cur_path = os.path.join(current_dir, \"fundamentals.json\")\n",
    "    write_json(funds_run_path, funds)\n",
    "    write_json(funds_cur_path, funds)\n",
    "\n",
    "    run_summary[\"fundamentals\"] = {\n",
    "        \"tickers\": FUND_TICKERS,\n",
    "        \"file_run\": funds_run_path,\n",
    "        \"file_current\": funds_cur_path,\n",
    "        \"source\": \"csv\",\n",
    "        \"csv_path\": CSV_METRICS_PATH,\n",
    "        \"fields\": [\"marketcap\", \"pb_current\", \"pb_current_pctile\", \"div_y\"]\n",
    "    }\n",
    "\n",
    "    # ---- Save summary ----\n",
    "    write_json(os.path.join(run_dir, \"summary.json\"), run_summary)\n",
    "    write_json(os.path.join(current_dir, \"summary.json\"), run_summary)\n",
    "\n",
    "    # ---- Auto-commit & push ----\n",
    "    git_commit_and_push(\n",
    "        repo_root=base_dir,\n",
    "        run_dir=run_dir,\n",
    "        current_dir=current_dir,\n",
    "        branch=\"main\"\n",
    "    )\n",
    "\n",
    "    print(\"üèÅ Done.\")\n",
    "    if run_summary[\"errors\"]:\n",
    "        print(\"Some symbols failed (see summary.json).\")\n",
    "    else:\n",
    "        print(\"All symbols fetched successfully.\")\n",
    "    print(f\"Latest 'current' folder ready for Qualtrics: {current_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f48f4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Daily archive folder: /Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Programming/Git/pilot3-asset-data/finaltest/stocks/runs/run_2025-12-18\n",
      "üìÇ Current folder for Qualtrics: /Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Programming/Git/pilot3-asset-data/finaltest/stocks/current\n",
      "‚è≥ Fetching 365-day data for CSCO‚Ä¶\n",
      " ‚úÖ Wrote csco_365d.json (250 points)\n",
      "‚è≥ Fetching 365-day data for MSFT‚Ä¶\n",
      " ‚úÖ Wrote msft_365d.json (250 points)\n",
      "‚è≥ Fetching 365-day data for TER‚Ä¶\n",
      " ‚úÖ Wrote ter_365d.json (250 points)\n",
      "‚è≥ Fetching 365-day data for AKAM‚Ä¶\n",
      " ‚úÖ Wrote akam_365d.json (250 points)\n",
      "‚è≥ Fetching 365-day data for NTAP‚Ä¶\n",
      " ‚úÖ Wrote ntap_365d.json (250 points)\n",
      "‚è≥ Fetching 365-day data for AMKR‚Ä¶\n",
      " ‚úÖ Wrote amkr_365d.json (250 points)\n",
      "Has MSFT exact?: True\n",
      "MSFT-like keys: ['MSFT']\n",
      "‚úÖ Pushed to origin; GitHub Action will purge jsDelivr cache.\n",
      "üèÅ Done.\n",
      "All symbols fetched successfully.\n",
      "Latest 'current' folder ready for Qualtrics: /Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Programming/Git/pilot3-asset-data/finaltest/stocks/current\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To github.com:pagrass/pilot1-asset-data.git\n",
      "   dd69c46..f4035fc  main -> main\n"
     ]
    }
   ],
   "source": [
    "#Code Stocks\n",
    "\n",
    "import csv\n",
    "import subprocess\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Deps: pip install yfinance\n",
    "import yfinance as yf\n",
    "\n",
    "# -------------------- Config --------------------\n",
    "\n",
    "STOCKS  = [\"CSCO\", \"MSFT\", \"TER\", \"AKAM\", \"NTAP\", \"AMKR\"]\n",
    "\n",
    "#Replication cryptos\n",
    "\n",
    "\n",
    "#CRYPTOS = [\"BCH-USD\", \"ETH-USD\", \"XMR-USD\"] \n",
    "\n",
    "#Own predictions cryptos\n",
    "#CRYPTOS = [\"XRP-USD\", \"BNB-USD\", \"BTC-USD\"]\n",
    "\n",
    "#All cryptos\n",
    "#CRYPTOS = [\"BTC-USD\", \"XMR-USD\", \"BNB-USD\", \"BCH-USD\", \"ETH-USD\", \"TRX-USD\"]\n",
    "\n",
    "TICKERS = STOCKS\n",
    "#+ CRYPTOS\n",
    "\n",
    "FUND_TICKERS = [\"CSCO\", \"MSFT\", \"TER\", \"AKAM\", \"NTAP\", \"AMKR\"]\n",
    "\n",
    "SECTOR_MAP = {\n",
    "    \"CSCO\": \"Information Technology\",\n",
    "    \"MSFT\": \"Information Technology\",\n",
    "    \"TER\": \"Information Technology\",\n",
    "    \"AKAM\": \"Information Technology\",\n",
    "    \"NTAP\":  \"Information Technology\",\n",
    "    \"AMKR\":   \"Information Technology\",\n",
    "}\n",
    "\n",
    "# Date window\n",
    "END   = datetime.now()\n",
    "START = END - timedelta(days=365)\n",
    "\n",
    "# Default base dir (each run gets a new subfolder here)\n",
    "DEFAULT_BASE_DIR = \"/Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Programming/Git/pilot3-asset-data/finaltest/stocks\"\n",
    "\n",
    "# Path to CSV ‚Äúdictionary‚Äù\n",
    "CSV_METRICS_PATH = \"/Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Model Spillovers/Data/Stock Selection/preselection/candidate_subset_all.csv\"\n",
    "\n",
    "# Rate limiting\n",
    "SLEEP_BETWEEN_TICKERS_SEC = 10\n",
    "MAX_RETRIES = 3\n",
    "RETRY_DELAY_SEC = 5\n",
    "\n",
    "# Safety: never allow writing into these substrings\n",
    "FORBIDDEN_SUBSTRINGS = [\"pilot2-asset-data\"]\n",
    "\n",
    "# -------------------- Helpers --------------------\n",
    "\n",
    "def git_commit_and_push(repo_root: str, run_dir: str, current_dir: str, branch: str = \"main\"):\n",
    "    # Only commit if there are changes in current/ or today's run folder\n",
    "    rel_run = os.path.relpath(run_dir, repo_root)\n",
    "    rel_cur = os.path.relpath(current_dir, repo_root)\n",
    "\n",
    "    cwd_before = os.getcwd()\n",
    "    os.chdir(repo_root)\n",
    "    try:\n",
    "        diff = subprocess.run(\n",
    "            [\"git\", \"status\", \"--porcelain\", rel_cur, rel_run],\n",
    "            capture_output=True, text=True\n",
    "        )\n",
    "        if diff.returncode != 0:\n",
    "            print(\"‚ö†Ô∏è  git status failed; not pushing.\")\n",
    "            return\n",
    "        if diff.stdout.strip() == \"\":\n",
    "            print(\"‚ÑπÔ∏è  No changes to commit; skipping push.\")\n",
    "            return\n",
    "\n",
    "        # Stage just what we care about\n",
    "        subprocess.run([\"git\", \"add\", rel_cur, rel_run], check=True)\n",
    "\n",
    "        # Commit\n",
    "        msg = f\"Update data: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "        commit = subprocess.run([\"git\", \"commit\", \"-m\", msg], capture_output=True, text=True)\n",
    "        if commit.returncode != 0:\n",
    "            print(commit.stdout or commit.stderr or \"‚ÑπÔ∏è  Nothing to commit.\")\n",
    "            return\n",
    "\n",
    "        # Push\n",
    "        subprocess.run([\"git\", \"push\", \"origin\", branch], check=True)\n",
    "        print(\"‚úÖ Pushed to origin; GitHub Action will purge jsDelivr cache.\")\n",
    "    finally:\n",
    "        os.chdir(cwd_before)\n",
    "\n",
    "def guard_path(path: str):\n",
    "    norm = os.path.normpath(path)\n",
    "    for bad in FORBIDDEN_SUBSTRINGS:\n",
    "        if bad in norm:\n",
    "            raise RuntimeError(f\"Refusing to write into forbidden path: {norm}\")\n",
    "\n",
    "def safe_mkdirs(path: str):\n",
    "    guard_path(path)\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "def make_daily_run_dir(base_dir: str) -> str:\n",
    "    date_str = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    run_dir = os.path.join(base_dir, \"runs\", f\"run_{date_str}\")\n",
    "    safe_mkdirs(run_dir)\n",
    "    return run_dir\n",
    "\n",
    "def ensure_current_dir(base_dir: str) -> str:\n",
    "    cur = os.path.join(base_dir, \"current\")\n",
    "    safe_mkdirs(cur)\n",
    "    return cur\n",
    "\n",
    "def copy_to_current(src_path: str, current_dir: str):\n",
    "    guard_path(current_dir)\n",
    "    dst_path = os.path.join(current_dir, os.path.basename(src_path))\n",
    "    with open(src_path, \"rb\") as s, open(dst_path, \"wb\") as d:\n",
    "        d.write(s.read())\n",
    "    return dst_path\n",
    "\n",
    "def write_json(path: str, obj):\n",
    "    guard_path(path)\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(obj, f, indent=2)\n",
    "\n",
    "# ---------- CSV metrics ----------\n",
    "\n",
    "def _coerce_number(val):\n",
    "    \"\"\"Coerce CSV field to float if possible; return None for empty/invalid.\"\"\"\n",
    "    if val is None:\n",
    "        return None\n",
    "    s = str(val).strip()\n",
    "    if s == \"\" or s.lower() in {\"na\", \"nan\", \"none\"}:\n",
    "        return None\n",
    "    try:\n",
    "        return float(s.replace(\",\", \"\"))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def fetch_metrics_from_csv(symbols, csv_path, sector_map=None):\n",
    "    \"\"\"\n",
    "    Pull marketcap, pb_current, pb_current_pctile, div_y from a CSV keyed by ticker.\n",
    "\n",
    "    Post-processing:\n",
    "      - marketcap -> divide by 1,000,000 and round to 2 decimals (millions)\n",
    "      - pb_current_pctile -> round to 2 decimals\n",
    "      - div_y (aka div_yield/dividend_yield) -> divide by 100 (to decimal)\n",
    "      - valuation (new): Low / Mid / High based on pb_current_pctile\n",
    "    \"\"\"\n",
    "    lookup = {}\n",
    "    with open(csv_path, newline=\"\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            row_lower = {k.lower(): v for k, v in row.items()}\n",
    "            tk = (row_lower.get(\"ticker\") or row_lower.get(\"symbol\") or \"\").strip().upper()\n",
    "            if tk:\n",
    "                lookup[tk] = row_lower\n",
    "\n",
    "    print(\"Has MSFT exact?:\", \"MSFT\" in lookup)\n",
    "\n",
    "    # show any keys that \"contain\" MSFT (suffixes, weird formats)\n",
    "    msft_like = [k for k in lookup.keys() if \"MSFT\" in k]\n",
    "    print(\"MSFT-like keys:\", msft_like[:50])\n",
    "    out = {}\n",
    "    for sym in symbols:\n",
    "        key = sym.upper()\n",
    "        row = lookup.get(key)\n",
    "        if not row:\n",
    "            out[key] = {\"error\": \"Ticker not found in CSV\", \"sector\": (sector_map or {}).get(key)}\n",
    "            continue\n",
    "\n",
    "        mc_raw = _coerce_number(row.get(\"marketcap\"))\n",
    "        pb = _coerce_number(row.get(\"pb_current\"))\n",
    "        pb_pct_raw = _coerce_number(row.get(\"pb_current_pctile\"))\n",
    "\n",
    "        # Flexible dividend yield column handling\n",
    "        div_candidates = [\"div_y\", \"div_yield\", \"dividend_yield\"]\n",
    "        div_raw = None\n",
    "        for c in div_candidates:\n",
    "            if c in row:\n",
    "                div_raw = _coerce_number(row.get(c))\n",
    "                if div_raw is not None:\n",
    "                    break\n",
    "\n",
    "        # ---- Post-processing transforms ----\n",
    "        mc_millions = round(mc_raw / 1_000_000, 2) if mc_raw is not None else None\n",
    "        pb_pct = round(pb_pct_raw * 100, 0) if pb_pct_raw is not None else None\n",
    "        div_val = (div_raw) if div_raw is not None else None\n",
    "\n",
    "        # ---- Valuation classification ----\n",
    "        if pb_pct is None:\n",
    "            valuation = None\n",
    "        elif pb_pct <= 30:\n",
    "            valuation = \"Low\"\n",
    "        elif pb_pct >= 70:\n",
    "            valuation = \"High\"\n",
    "        else:\n",
    "            valuation = \"Mid\"\n",
    "\n",
    "        out[key] = {\n",
    "            \"marketcap\": mc_millions,\n",
    "            \"pb_current\": pb,\n",
    "            \"pb_current_pctile\": pb_pct,\n",
    "            \"div_y\": div_val,\n",
    "            \"valuation\": valuation,   # üëà new field\n",
    "        }\n",
    "        if sector_map:\n",
    "            out[key][\"sector\"] = sector_map.get(key)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# -------------------- Main --------------------\n",
    "\n",
    "def main():\n",
    "    base_dir = os.getenv(\"DATA_BASE_DIR\", DEFAULT_BASE_DIR)\n",
    "    guard_path(base_dir)\n",
    "    safe_mkdirs(base_dir)\n",
    "\n",
    "    run_dir = make_daily_run_dir(base_dir)\n",
    "    current_dir = ensure_current_dir(base_dir)\n",
    "\n",
    "    print(f\"üìÅ Daily archive folder: {run_dir}\")\n",
    "    print(f\"üìÇ Current folder for Qualtrics: {current_dir}\")\n",
    "\n",
    "    run_summary = {\n",
    "        \"started_at\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "        \"window_start\": START.strftime(\"%Y-%m-%d\"),\n",
    "        \"window_end\": END.strftime(\"%Y-%m-%d\"),\n",
    "        \"files\": [],\n",
    "        \"errors\": [],\n",
    "    }\n",
    "\n",
    "    # ---- Price history (yfinance) ----\n",
    "    for sym in TICKERS:\n",
    "        print(f\"‚è≥ Fetching 365-day data for {sym}‚Ä¶\")\n",
    "        last_err = None\n",
    "        for attempt in range(1, MAX_RETRIES + 1):\n",
    "            try:\n",
    "                tkr = yf.Ticker(sym)\n",
    "                df = tkr.history(\n",
    "                    start=START.strftime(\"%Y-%m-%d\"),\n",
    "                    end=END.strftime(\"%Y-%m-%d\"),\n",
    "                    auto_adjust=True,\n",
    "                )\n",
    "                if df is None or df.empty:\n",
    "                    raise ValueError(\"Empty dataframe returned.\")\n",
    "\n",
    "                pts = [\n",
    "                    [int(row_ts.timestamp() * 1000), round(float(row[\"Close\"]), 2)]\n",
    "                    for row_ts, row in df.iterrows()\n",
    "                    if row.get(\"Close\") is not None\n",
    "                ]\n",
    "                if not pts:\n",
    "                    raise ValueError(\"No valid close prices found.\")\n",
    "\n",
    "                out_sym = sym.replace(\"-USD\", \"\").replace(\".\", \"\").lower()\n",
    "\n",
    "                out_path = os.path.join(run_dir, f\"{out_sym}_365d.json\")\n",
    "                write_json(out_path, {\"prices\": pts})\n",
    "\n",
    "                copy_to_current(out_path, current_dir)\n",
    "\n",
    "                print(f\" ‚úÖ Wrote {out_sym}_365d.json ({len(pts)} points)\")\n",
    "\n",
    "                run_summary[\"files\"].append({\n",
    "                    \"symbol\": sym,\n",
    "                    \"file\": out_path,\n",
    "                    \"points\": len(pts),\n",
    "                    \"first_ts\": pts[0][0],\n",
    "                    \"last_ts\": pts[-1][0],\n",
    "                })\n",
    "                last_err = None\n",
    "                break\n",
    "            except Exception as e:\n",
    "                last_err = str(e)\n",
    "                print(f\"   ‚ö†Ô∏è Attempt {attempt}/{MAX_RETRIES} failed: {last_err}\")\n",
    "                if attempt < MAX_RETRIES:\n",
    "                    time.sleep(RETRY_DELAY_SEC)\n",
    "\n",
    "        if last_err:\n",
    "            run_summary[\"errors\"].append({\"symbol\": sym, \"error\": last_err})\n",
    "\n",
    "        time.sleep(SLEEP_BETWEEN_TICKERS_SEC)\n",
    "\n",
    "    # ---- Metrics from CSV (no Yahoo fundamentals) ----\n",
    "    try:\n",
    "        funds = fetch_metrics_from_csv(\n",
    "            FUND_TICKERS,\n",
    "            CSV_METRICS_PATH,\n",
    "            sector_map=SECTOR_MAP\n",
    "        )\n",
    "    except Exception as e:\n",
    "        funds = {sym: {\"error\": f\"CSV read failed: {e}\", \"sector\": SECTOR_MAP.get(sym)} for sym in FUND_TICKERS}\n",
    "\n",
    "    funds_run_path = os.path.join(run_dir, \"fundamentals.json\")\n",
    "    funds_cur_path = os.path.join(current_dir, \"fundamentals.json\")\n",
    "    write_json(funds_run_path, funds)\n",
    "    write_json(funds_cur_path, funds)\n",
    "\n",
    "    run_summary[\"fundamentals\"] = {\n",
    "        \"tickers\": FUND_TICKERS,\n",
    "        \"file_run\": funds_run_path,\n",
    "        \"file_current\": funds_cur_path,\n",
    "        \"source\": \"csv\",\n",
    "        \"csv_path\": CSV_METRICS_PATH,\n",
    "        \"fields\": [\"marketcap\", \"pb_current\", \"pb_current_pctile\", \"div_y\"]\n",
    "    }\n",
    "\n",
    "    # ---- Save summary ----\n",
    "    write_json(os.path.join(run_dir, \"summary.json\"), run_summary)\n",
    "    write_json(os.path.join(current_dir, \"summary.json\"), run_summary)\n",
    "\n",
    "    # ---- Auto-commit & push ----\n",
    "    git_commit_and_push(\n",
    "        repo_root=base_dir,\n",
    "        run_dir=run_dir,\n",
    "        current_dir=current_dir,\n",
    "        branch=\"main\"\n",
    "    )\n",
    "\n",
    "    print(\"üèÅ Done.\")\n",
    "    if run_summary[\"errors\"]:\n",
    "        print(\"Some symbols failed (see summary.json).\")\n",
    "    else:\n",
    "        print(\"All symbols fetched successfully.\")\n",
    "    print(f\"Latest 'current' folder ready for Qualtrics: {current_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7343669d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Daily archive folder: /Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Programming/Git/pilot3-asset-data/main/replicationcryptos/runs/run_2025-12-17\n",
      "üìÇ Current folder for Qualtrics: /Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Programming/Git/pilot3-asset-data/main/replicationcryptos/current\n",
      "‚è≥ Fetching 365-day data for ETH-USD‚Ä¶\n",
      " ‚úÖ Wrote eth_365d.json (365 points)\n",
      "‚è≥ Fetching 365-day data for XMR-USD‚Ä¶\n",
      " ‚úÖ Wrote xmr_365d.json (365 points)\n",
      "‚è≥ Fetching 365-day data for BCH-USD‚Ä¶\n",
      " ‚úÖ Wrote bch_365d.json (365 points)\n",
      "‚úÖ Pushed to origin; GitHub Action will purge jsDelivr cache.\n",
      "üèÅ Done.\n",
      "All symbols fetched successfully.\n",
      "Latest 'current' folder ready for Qualtrics: /Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Programming/Git/pilot3-asset-data/main/replicationcryptos/current\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To github.com:pagrass/pilot1-asset-data.git\n",
      "   d0dca68..60e1150  main -> main\n"
     ]
    }
   ],
   "source": [
    "#CODE Own Belief Cryptos\n",
    "import csv\n",
    "import subprocess\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Deps: pip install yfinance\n",
    "import yfinance as yf\n",
    "\n",
    "# -------------------- Config --------------------\n",
    "\n",
    "#STOCKS  = [\"CSCO\", \"TMUS\", \"TWLO\", \"PEGA\", \"ROG\", \"PD\"]\n",
    "\n",
    "#Replication cryptos\n",
    "\n",
    "\n",
    "#CRYPTOS = [\"BCH-USD\", \"ETH-USD\", \"XMR-USD\"] \n",
    "\n",
    "#Own predictions cryptos\n",
    "#CRYPTOS = [\"XRP-USD\", \"BNB-USD\", \"BTC-USD\"]\n",
    "\n",
    "#All cryptos\n",
    "CRYPTOS = [\"ETH-USD\", \"XMR-USD\", \"BCH-USD\", \"\"]\n",
    "\n",
    "TICKERS = CRYPTOS\n",
    "#+ CRYPTOS\n",
    "\n",
    "FUND_TICKERS = [\"CSCO\", \"TMUS\", \"TWLO\", \"PEGA\", \"ROG\", \"PD\"]\n",
    "\n",
    "SECTOR_MAP = {\n",
    "    \"CSCO\": \"Information Technology\",\n",
    "    \"TMUS\": \"Communication Services\",\n",
    "    \"TWLO\": \"Information Technology\",\n",
    "    \"PEGA\": \"Information Technology\",\n",
    "    \"ROG\":  \"Information Technology\",\n",
    "    \"PD\":   \"Information Technology\",\n",
    "}\n",
    "\n",
    "# Date window\n",
    "END   = datetime.now()\n",
    "START = END - timedelta(days=365)\n",
    "\n",
    "# Default base dir (each run gets a new subfolder here)\n",
    "DEFAULT_BASE_DIR = \"/Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Programming/Git/pilot3-asset-data/main/replicationcryptos\"\n",
    "\n",
    "# Path to CSV ‚Äúdictionary‚Äù\n",
    "CSV_METRICS_PATH = \"/Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Model Spillovers/Data/Stock Selection/preselection/candidate_subset_all.csv\"\n",
    "\n",
    "# Rate limiting\n",
    "SLEEP_BETWEEN_TICKERS_SEC = 10\n",
    "MAX_RETRIES = 3\n",
    "RETRY_DELAY_SEC = 5\n",
    "\n",
    "# Safety: never allow writing into these substrings\n",
    "FORBIDDEN_SUBSTRINGS = [\"pilot2-asset-data\"]\n",
    "\n",
    "# -------------------- Helpers --------------------\n",
    "\n",
    "def git_commit_and_push(repo_root: str, run_dir: str, current_dir: str, branch: str = \"main\"):\n",
    "    # Only commit if there are changes in current/ or today's run folder\n",
    "    rel_run = os.path.relpath(run_dir, repo_root)\n",
    "    rel_cur = os.path.relpath(current_dir, repo_root)\n",
    "\n",
    "    cwd_before = os.getcwd()\n",
    "    os.chdir(repo_root)\n",
    "    try:\n",
    "        diff = subprocess.run(\n",
    "            [\"git\", \"status\", \"--porcelain\", rel_cur, rel_run],\n",
    "            capture_output=True, text=True\n",
    "        )\n",
    "        if diff.returncode != 0:\n",
    "            print(\"‚ö†Ô∏è  git status failed; not pushing.\")\n",
    "            return\n",
    "        if diff.stdout.strip() == \"\":\n",
    "            print(\"‚ÑπÔ∏è  No changes to commit; skipping push.\")\n",
    "            return\n",
    "\n",
    "        # Stage just what we care about\n",
    "        subprocess.run([\"git\", \"add\", rel_cur, rel_run], check=True)\n",
    "\n",
    "        # Commit\n",
    "        msg = f\"Update data: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "        commit = subprocess.run([\"git\", \"commit\", \"-m\", msg], capture_output=True, text=True)\n",
    "        if commit.returncode != 0:\n",
    "            print(commit.stdout or commit.stderr or \"‚ÑπÔ∏è  Nothing to commit.\")\n",
    "            return\n",
    "\n",
    "        # Push\n",
    "        subprocess.run([\"git\", \"push\", \"origin\", branch], check=True)\n",
    "        print(\"‚úÖ Pushed to origin; GitHub Action will purge jsDelivr cache.\")\n",
    "    finally:\n",
    "        os.chdir(cwd_before)\n",
    "\n",
    "def guard_path(path: str):\n",
    "    norm = os.path.normpath(path)\n",
    "    for bad in FORBIDDEN_SUBSTRINGS:\n",
    "        if bad in norm:\n",
    "            raise RuntimeError(f\"Refusing to write into forbidden path: {norm}\")\n",
    "\n",
    "def safe_mkdirs(path: str):\n",
    "    guard_path(path)\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "def make_daily_run_dir(base_dir: str) -> str:\n",
    "    date_str = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    run_dir = os.path.join(base_dir, \"runs\", f\"run_{date_str}\")\n",
    "    safe_mkdirs(run_dir)\n",
    "    return run_dir\n",
    "\n",
    "def ensure_current_dir(base_dir: str) -> str:\n",
    "    cur = os.path.join(base_dir, \"current\")\n",
    "    safe_mkdirs(cur)\n",
    "    return cur\n",
    "\n",
    "def copy_to_current(src_path: str, current_dir: str):\n",
    "    guard_path(current_dir)\n",
    "    dst_path = os.path.join(current_dir, os.path.basename(src_path))\n",
    "    with open(src_path, \"rb\") as s, open(dst_path, \"wb\") as d:\n",
    "        d.write(s.read())\n",
    "    return dst_path\n",
    "\n",
    "def write_json(path: str, obj):\n",
    "    guard_path(path)\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(obj, f, indent=2)\n",
    "\n",
    "# ---------- CSV metrics ----------\n",
    "\n",
    "def _coerce_number(val):\n",
    "    \"\"\"Coerce CSV field to float if possible; return None for empty/invalid.\"\"\"\n",
    "    if val is None:\n",
    "        return None\n",
    "    s = str(val).strip()\n",
    "    if s == \"\" or s.lower() in {\"na\", \"nan\", \"none\"}:\n",
    "        return None\n",
    "    try:\n",
    "        return float(s.replace(\",\", \"\"))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def fetch_metrics_from_csv(symbols, csv_path, sector_map=None):\n",
    "    \"\"\"\n",
    "    Pull marketcap, pb_current, pb_current_pctile, div_y from a CSV keyed by ticker.\n",
    "\n",
    "    Post-processing:\n",
    "      - marketcap -> divide by 1,000,000 and round to 2 decimals (millions)\n",
    "      - pb_current_pctile -> round to 2 decimals\n",
    "      - div_y (aka div_yield/dividend_yield) -> divide by 100 (to decimal)\n",
    "      - valuation (new): Low / Mid / High based on pb_current_pctile\n",
    "    \"\"\"\n",
    "    lookup = {}\n",
    "    with open(csv_path, newline=\"\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            row_lower = {k.lower(): v for k, v in row.items()}\n",
    "            tk = (row_lower.get(\"ticker\") or row_lower.get(\"symbol\") or \"\").strip().upper()\n",
    "            if tk:\n",
    "                lookup[tk] = row_lower\n",
    "\n",
    "    out = {}\n",
    "    for sym in symbols:\n",
    "        key = sym.upper()\n",
    "        row = lookup.get(key)\n",
    "        if not row:\n",
    "            out[key] = {\"error\": \"Ticker not found in CSV\", \"sector\": (sector_map or {}).get(key)}\n",
    "            continue\n",
    "\n",
    "        mc_raw = _coerce_number(row.get(\"marketcap\"))\n",
    "        pb = _coerce_number(row.get(\"pb_current\"))\n",
    "        pb_pct_raw = _coerce_number(row.get(\"pb_current_pctile\"))\n",
    "\n",
    "        # Flexible dividend yield column handling\n",
    "        div_candidates = [\"div_y\", \"div_yield\", \"dividend_yield\"]\n",
    "        div_raw = None\n",
    "        for c in div_candidates:\n",
    "            if c in row:\n",
    "                div_raw = _coerce_number(row.get(c))\n",
    "                if div_raw is not None:\n",
    "                    break\n",
    "\n",
    "        # ---- Post-processing transforms ----\n",
    "        mc_millions = round(mc_raw / 1_000_000, 2) if mc_raw is not None else None\n",
    "        pb_pct = round(pb_pct_raw * 100, 0) if pb_pct_raw is not None else None\n",
    "        div_val = (div_raw) if div_raw is not None else None\n",
    "\n",
    "        # ---- Valuation classification ----\n",
    "        if pb_pct is None:\n",
    "            valuation = None\n",
    "        elif pb_pct <= 33:\n",
    "            valuation = \"Low\"\n",
    "        elif pb_pct >= 67:\n",
    "            valuation = \"High\"\n",
    "        else:\n",
    "            valuation = \"Mid\"\n",
    "\n",
    "        out[key] = {\n",
    "            \"marketcap\": mc_millions,\n",
    "            \"pb_current\": pb,\n",
    "            \"pb_current_pctile\": pb_pct,\n",
    "            \"div_y\": div_val,\n",
    "            \"valuation\": valuation,   # üëà new field\n",
    "        }\n",
    "        if sector_map:\n",
    "            out[key][\"sector\"] = sector_map.get(key)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# -------------------- Main --------------------\n",
    "\n",
    "def main():\n",
    "    base_dir = os.getenv(\"DATA_BASE_DIR\", DEFAULT_BASE_DIR)\n",
    "    guard_path(base_dir)\n",
    "    safe_mkdirs(base_dir)\n",
    "\n",
    "    run_dir = make_daily_run_dir(base_dir)\n",
    "    current_dir = ensure_current_dir(base_dir)\n",
    "\n",
    "    print(f\"üìÅ Daily archive folder: {run_dir}\")\n",
    "    print(f\"üìÇ Current folder for Qualtrics: {current_dir}\")\n",
    "\n",
    "    run_summary = {\n",
    "        \"started_at\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "        \"window_start\": START.strftime(\"%Y-%m-%d\"),\n",
    "        \"window_end\": END.strftime(\"%Y-%m-%d\"),\n",
    "        \"files\": [],\n",
    "        \"errors\": [],\n",
    "    }\n",
    "\n",
    "    # ---- Price history (yfinance) ----\n",
    "    for sym in TICKERS:\n",
    "        print(f\"‚è≥ Fetching 365-day data for {sym}‚Ä¶\")\n",
    "        last_err = None\n",
    "        for attempt in range(1, MAX_RETRIES + 1):\n",
    "            try:\n",
    "                tkr = yf.Ticker(sym)\n",
    "                df = tkr.history(\n",
    "                    start=START.strftime(\"%Y-%m-%d\"),\n",
    "                    end=END.strftime(\"%Y-%m-%d\"),\n",
    "                    auto_adjust=True,\n",
    "                )\n",
    "                if df is None or df.empty:\n",
    "                    raise ValueError(\"Empty dataframe returned.\")\n",
    "\n",
    "                pts = [\n",
    "                    [int(row_ts.timestamp() * 1000), round(float(row[\"Close\"]), 2)]\n",
    "                    for row_ts, row in df.iterrows()\n",
    "                    if row.get(\"Close\") is not None\n",
    "                ]\n",
    "                if not pts:\n",
    "                    raise ValueError(\"No valid close prices found.\")\n",
    "\n",
    "                out_sym = sym.replace(\"-USD\", \"\").replace(\".\", \"\").lower()\n",
    "\n",
    "                out_path = os.path.join(run_dir, f\"{out_sym}_365d.json\")\n",
    "                write_json(out_path, {\"prices\": pts})\n",
    "\n",
    "                copy_to_current(out_path, current_dir)\n",
    "\n",
    "                print(f\" ‚úÖ Wrote {out_sym}_365d.json ({len(pts)} points)\")\n",
    "\n",
    "                run_summary[\"files\"].append({\n",
    "                    \"symbol\": sym,\n",
    "                    \"file\": out_path,\n",
    "                    \"points\": len(pts),\n",
    "                    \"first_ts\": pts[0][0],\n",
    "                    \"last_ts\": pts[-1][0],\n",
    "                })\n",
    "                last_err = None\n",
    "                break\n",
    "            except Exception as e:\n",
    "                last_err = str(e)\n",
    "                print(f\"   ‚ö†Ô∏è Attempt {attempt}/{MAX_RETRIES} failed: {last_err}\")\n",
    "                if attempt < MAX_RETRIES:\n",
    "                    time.sleep(RETRY_DELAY_SEC)\n",
    "\n",
    "        if last_err:\n",
    "            run_summary[\"errors\"].append({\"symbol\": sym, \"error\": last_err})\n",
    "\n",
    "        time.sleep(SLEEP_BETWEEN_TICKERS_SEC)\n",
    "\n",
    "    # ---- Metrics from CSV (no Yahoo fundamentals) ----\n",
    "    try:\n",
    "        funds = fetch_metrics_from_csv(\n",
    "            FUND_TICKERS,\n",
    "            CSV_METRICS_PATH,\n",
    "            sector_map=SECTOR_MAP\n",
    "        )\n",
    "    except Exception as e:\n",
    "        funds = {sym: {\"error\": f\"CSV read failed: {e}\", \"sector\": SECTOR_MAP.get(sym)} for sym in FUND_TICKERS}\n",
    "\n",
    "    funds_run_path = os.path.join(run_dir, \"fundamentals.json\")\n",
    "    funds_cur_path = os.path.join(current_dir, \"fundamentals.json\")\n",
    "    write_json(funds_run_path, funds)\n",
    "    write_json(funds_cur_path, funds)\n",
    "\n",
    "    run_summary[\"fundamentals\"] = {\n",
    "        \"tickers\": FUND_TICKERS,\n",
    "        \"file_run\": funds_run_path,\n",
    "        \"file_current\": funds_cur_path,\n",
    "        \"source\": \"csv\",\n",
    "        \"csv_path\": CSV_METRICS_PATH,\n",
    "        \"fields\": [\"marketcap\", \"pb_current\", \"pb_current_pctile\", \"div_y\"]\n",
    "    }\n",
    "\n",
    "    # ---- Save summary ----\n",
    "    write_json(os.path.join(run_dir, \"summary.json\"), run_summary)\n",
    "    write_json(os.path.join(current_dir, \"summary.json\"), run_summary)\n",
    "\n",
    "    # ---- Auto-commit & push ----\n",
    "    git_commit_and_push(\n",
    "        repo_root=base_dir,\n",
    "        run_dir=run_dir,\n",
    "        current_dir=current_dir,\n",
    "        branch=\"main\"\n",
    "    )\n",
    "\n",
    "    print(\"üèÅ Done.\")\n",
    "    if run_summary[\"errors\"]:\n",
    "        print(\"Some symbols failed (see summary.json).\")\n",
    "    else:\n",
    "        print(\"All symbols fetched successfully.\")\n",
    "    print(f\"Latest 'current' folder ready for Qualtrics: {current_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473e2f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Daily archive folder: /Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Programming/Git/pilot3-asset-data/finalpilot/crypto/runs/run_2025-12-17\n",
      "üìÇ Current folder for Qualtrics: /Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Programming/Git/pilot3-asset-data/finalpilot/crypto/current\n",
      "‚è≥ Fetching 365-day data for BTC-USD‚Ä¶\n",
      " ‚úÖ Wrote btc_365d.json (365 points)\n",
      "‚è≥ Fetching 365-day data for XMR-USD‚Ä¶\n",
      " ‚úÖ Wrote xmr_365d.json (365 points)\n",
      "‚è≥ Fetching 365-day data for BNB-USD‚Ä¶\n",
      " ‚úÖ Wrote bnb_365d.json (365 points)\n",
      "‚è≥ Fetching 365-day data for BCH-USD‚Ä¶\n",
      " ‚úÖ Wrote bch_365d.json (365 points)\n",
      "‚è≥ Fetching 365-day data for ETH-USD‚Ä¶\n",
      " ‚úÖ Wrote eth_365d.json (365 points)\n",
      "‚è≥ Fetching 365-day data for TRX-USD‚Ä¶\n",
      " ‚úÖ Wrote trx_365d.json (365 points)\n",
      "‚úÖ Pushed to origin; GitHub Action will purge jsDelivr cache.\n",
      "üèÅ Done.\n",
      "All symbols fetched successfully.\n",
      "Latest 'current' folder ready for Qualtrics: /Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Programming/Git/pilot3-asset-data/finalpilot/crypto/current\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To github.com:pagrass/pilot1-asset-data.git\n",
      "   41c355a..5045671  main -> main\n"
     ]
    }
   ],
   "source": [
    "#CODE Own Belief Cryptos\n",
    "import csv\n",
    "import subprocess\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Deps: pip install yfinance\n",
    "import yfinance as yf\n",
    "\n",
    "# -------------------- Config --------------------\n",
    "\n",
    "#STOCKS  = [\"CSCO\", \"TMUS\", \"TWLO\", \"PEGA\", \"ROG\", \"PD\"]\n",
    "\n",
    "#Replication cryptos\n",
    "\n",
    "\n",
    "#CRYPTOS = [\"BCH-USD\", \"ETH-USD\", \"XMR-USD\"] \n",
    "\n",
    "#Own predictions cryptos\n",
    "#CRYPTOS = [\"XRP-USD\", \"BNB-USD\", \"BTC-USD\"]\n",
    "\n",
    "#All cryptos\n",
    "CRYPTOS = [\"BTC-USD\", \"XMR-USD\", \"BNB-USD\", \"BCH-USD\", \"ETH-USD\", \"TRX-USD\"]\n",
    "\n",
    "TICKERS = CRYPTOS\n",
    "#+ CRYPTOS\n",
    "\n",
    "FUND_TICKERS = [\"CSCO\", \"TMUS\", \"TWLO\", \"PEGA\", \"ROG\", \"PD\"]\n",
    "\n",
    "SECTOR_MAP = {\n",
    "    \"CSCO\": \"Information Technology\",\n",
    "    \"TMUS\": \"Communication Services\",\n",
    "    \"TWLO\": \"Information Technology\",\n",
    "    \"PEGA\": \"Information Technology\",\n",
    "    \"ROG\":  \"Information Technology\",\n",
    "    \"PD\":   \"Information Technology\",\n",
    "}\n",
    "\n",
    "# Date window\n",
    "END   = datetime.now()\n",
    "START = END - timedelta(days=365)\n",
    "\n",
    "# Default base dir (each run gets a new subfolder here)\n",
    "DEFAULT_BASE_DIR = \"/Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Programming/Git/pilot3-asset-data/finalpilot/crypto\"\n",
    "\n",
    "# Path to CSV ‚Äúdictionary‚Äù\n",
    "CSV_METRICS_PATH = \"/Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Model Spillovers/Data/Stock Selection/preselection/candidate_subset_all.csv\"\n",
    "\n",
    "# Rate limiting\n",
    "SLEEP_BETWEEN_TICKERS_SEC = 10\n",
    "MAX_RETRIES = 3\n",
    "RETRY_DELAY_SEC = 5\n",
    "\n",
    "# Safety: never allow writing into these substrings\n",
    "FORBIDDEN_SUBSTRINGS = [\"pilot2-asset-data\"]\n",
    "\n",
    "# -------------------- Helpers --------------------\n",
    "\n",
    "def git_commit_and_push(repo_root: str, run_dir: str, current_dir: str, branch: str = \"main\"):\n",
    "    # Only commit if there are changes in current/ or today's run folder\n",
    "    rel_run = os.path.relpath(run_dir, repo_root)\n",
    "    rel_cur = os.path.relpath(current_dir, repo_root)\n",
    "\n",
    "    cwd_before = os.getcwd()\n",
    "    os.chdir(repo_root)\n",
    "    try:\n",
    "        diff = subprocess.run(\n",
    "            [\"git\", \"status\", \"--porcelain\", rel_cur, rel_run],\n",
    "            capture_output=True, text=True\n",
    "        )\n",
    "        if diff.returncode != 0:\n",
    "            print(\"‚ö†Ô∏è  git status failed; not pushing.\")\n",
    "            return\n",
    "        if diff.stdout.strip() == \"\":\n",
    "            print(\"‚ÑπÔ∏è  No changes to commit; skipping push.\")\n",
    "            return\n",
    "\n",
    "        # Stage just what we care about\n",
    "        subprocess.run([\"git\", \"add\", rel_cur, rel_run], check=True)\n",
    "\n",
    "        # Commit\n",
    "        msg = f\"Update data: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "        commit = subprocess.run([\"git\", \"commit\", \"-m\", msg], capture_output=True, text=True)\n",
    "        if commit.returncode != 0:\n",
    "            print(commit.stdout or commit.stderr or \"‚ÑπÔ∏è  Nothing to commit.\")\n",
    "            return\n",
    "\n",
    "        # Push\n",
    "        subprocess.run([\"git\", \"push\", \"origin\", branch], check=True)\n",
    "        print(\"‚úÖ Pushed to origin; GitHub Action will purge jsDelivr cache.\")\n",
    "    finally:\n",
    "        os.chdir(cwd_before)\n",
    "\n",
    "def guard_path(path: str):\n",
    "    norm = os.path.normpath(path)\n",
    "    for bad in FORBIDDEN_SUBSTRINGS:\n",
    "        if bad in norm:\n",
    "            raise RuntimeError(f\"Refusing to write into forbidden path: {norm}\")\n",
    "\n",
    "def safe_mkdirs(path: str):\n",
    "    guard_path(path)\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "def make_daily_run_dir(base_dir: str) -> str:\n",
    "    date_str = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    run_dir = os.path.join(base_dir, \"runs\", f\"run_{date_str}\")\n",
    "    safe_mkdirs(run_dir)\n",
    "    return run_dir\n",
    "\n",
    "def ensure_current_dir(base_dir: str) -> str:\n",
    "    cur = os.path.join(base_dir, \"current\")\n",
    "    safe_mkdirs(cur)\n",
    "    return cur\n",
    "\n",
    "def copy_to_current(src_path: str, current_dir: str):\n",
    "    guard_path(current_dir)\n",
    "    dst_path = os.path.join(current_dir, os.path.basename(src_path))\n",
    "    with open(src_path, \"rb\") as s, open(dst_path, \"wb\") as d:\n",
    "        d.write(s.read())\n",
    "    return dst_path\n",
    "\n",
    "def write_json(path: str, obj):\n",
    "    guard_path(path)\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(obj, f, indent=2)\n",
    "\n",
    "# ---------- CSV metrics ----------\n",
    "\n",
    "def _coerce_number(val):\n",
    "    \"\"\"Coerce CSV field to float if possible; return None for empty/invalid.\"\"\"\n",
    "    if val is None:\n",
    "        return None\n",
    "    s = str(val).strip()\n",
    "    if s == \"\" or s.lower() in {\"na\", \"nan\", \"none\"}:\n",
    "        return None\n",
    "    try:\n",
    "        return float(s.replace(\",\", \"\"))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def fetch_metrics_from_csv(symbols, csv_path, sector_map=None):\n",
    "    \"\"\"\n",
    "    Pull marketcap, pb_current, pb_current_pctile, div_y from a CSV keyed by ticker.\n",
    "\n",
    "    Post-processing:\n",
    "      - marketcap -> divide by 1,000,000 and round to 2 decimals (millions)\n",
    "      - pb_current_pctile -> round to 2 decimals\n",
    "      - div_y (aka div_yield/dividend_yield) -> divide by 100 (to decimal)\n",
    "      - valuation (new): Low / Mid / High based on pb_current_pctile\n",
    "    \"\"\"\n",
    "    lookup = {}\n",
    "    with open(csv_path, newline=\"\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            row_lower = {k.lower(): v for k, v in row.items()}\n",
    "            tk = (row_lower.get(\"ticker\") or row_lower.get(\"symbol\") or \"\").strip().upper()\n",
    "            if tk:\n",
    "                lookup[tk] = row_lower\n",
    "\n",
    "    out = {}\n",
    "    for sym in symbols:\n",
    "        key = sym.upper()\n",
    "        row = lookup.get(key)\n",
    "        if not row:\n",
    "            out[key] = {\"error\": \"Ticker not found in CSV\", \"sector\": (sector_map or {}).get(key)}\n",
    "            continue\n",
    "\n",
    "        mc_raw = _coerce_number(row.get(\"marketcap\"))\n",
    "        pb = _coerce_number(row.get(\"pb_current\"))\n",
    "        pb_pct_raw = _coerce_number(row.get(\"pb_current_pctile\"))\n",
    "\n",
    "        # Flexible dividend yield column handling\n",
    "        div_candidates = [\"div_y\", \"div_yield\", \"dividend_yield\"]\n",
    "        div_raw = None\n",
    "        for c in div_candidates:\n",
    "            if c in row:\n",
    "                div_raw = _coerce_number(row.get(c))\n",
    "                if div_raw is not None:\n",
    "                    break\n",
    "\n",
    "        # ---- Post-processing transforms ----\n",
    "        mc_millions = round(mc_raw / 1_000_000, 2) if mc_raw is not None else None\n",
    "        pb_pct = round(pb_pct_raw * 100, 0) if pb_pct_raw is not None else None\n",
    "        div_val = (div_raw) if div_raw is not None else None\n",
    "\n",
    "        # ---- Valuation classification ----\n",
    "        if pb_pct is None:\n",
    "            valuation = None\n",
    "        elif pb_pct <= 33:\n",
    "            valuation = \"Low\"\n",
    "        elif pb_pct >= 67:\n",
    "            valuation = \"High\"\n",
    "        else:\n",
    "            valuation = \"Mid\"\n",
    "\n",
    "        out[key] = {\n",
    "            \"marketcap\": mc_millions,\n",
    "            \"pb_current\": pb,\n",
    "            \"pb_current_pctile\": pb_pct,\n",
    "            \"div_y\": div_val,\n",
    "            \"valuation\": valuation,   # üëà new field\n",
    "        }\n",
    "        if sector_map:\n",
    "            out[key][\"sector\"] = sector_map.get(key)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# -------------------- Main --------------------\n",
    "\n",
    "def main():\n",
    "    base_dir = os.getenv(\"DATA_BASE_DIR\", DEFAULT_BASE_DIR)\n",
    "    guard_path(base_dir)\n",
    "    safe_mkdirs(base_dir)\n",
    "\n",
    "    run_dir = make_daily_run_dir(base_dir)\n",
    "    current_dir = ensure_current_dir(base_dir)\n",
    "\n",
    "    print(f\"üìÅ Daily archive folder: {run_dir}\")\n",
    "    print(f\"üìÇ Current folder for Qualtrics: {current_dir}\")\n",
    "\n",
    "    run_summary = {\n",
    "        \"started_at\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "        \"window_start\": START.strftime(\"%Y-%m-%d\"),\n",
    "        \"window_end\": END.strftime(\"%Y-%m-%d\"),\n",
    "        \"files\": [],\n",
    "        \"errors\": [],\n",
    "    }\n",
    "\n",
    "    # ---- Price history (yfinance) ----\n",
    "    for sym in TICKERS:\n",
    "        print(f\"‚è≥ Fetching 365-day data for {sym}‚Ä¶\")\n",
    "        last_err = None\n",
    "        for attempt in range(1, MAX_RETRIES + 1):\n",
    "            try:\n",
    "                tkr = yf.Ticker(sym)\n",
    "                df = tkr.history(\n",
    "                    start=START.strftime(\"%Y-%m-%d\"),\n",
    "                    end=END.strftime(\"%Y-%m-%d\"),\n",
    "                    auto_adjust=True,\n",
    "                )\n",
    "                if df is None or df.empty:\n",
    "                    raise ValueError(\"Empty dataframe returned.\")\n",
    "\n",
    "                pts = [\n",
    "                    [int(row_ts.timestamp() * 1000), round(float(row[\"Close\"]), 2)]\n",
    "                    for row_ts, row in df.iterrows()\n",
    "                    if row.get(\"Close\") is not None\n",
    "                ]\n",
    "                if not pts:\n",
    "                    raise ValueError(\"No valid close prices found.\")\n",
    "\n",
    "                out_sym = sym.replace(\"-USD\", \"\").replace(\".\", \"\").lower()\n",
    "\n",
    "                out_path = os.path.join(run_dir, f\"{out_sym}_365d.json\")\n",
    "                write_json(out_path, {\"prices\": pts})\n",
    "\n",
    "                copy_to_current(out_path, current_dir)\n",
    "\n",
    "                print(f\" ‚úÖ Wrote {out_sym}_365d.json ({len(pts)} points)\")\n",
    "\n",
    "                run_summary[\"files\"].append({\n",
    "                    \"symbol\": sym,\n",
    "                    \"file\": out_path,\n",
    "                    \"points\": len(pts),\n",
    "                    \"first_ts\": pts[0][0],\n",
    "                    \"last_ts\": pts[-1][0],\n",
    "                })\n",
    "                last_err = None\n",
    "                break\n",
    "            except Exception as e:\n",
    "                last_err = str(e)\n",
    "                print(f\"   ‚ö†Ô∏è Attempt {attempt}/{MAX_RETRIES} failed: {last_err}\")\n",
    "                if attempt < MAX_RETRIES:\n",
    "                    time.sleep(RETRY_DELAY_SEC)\n",
    "\n",
    "        if last_err:\n",
    "            run_summary[\"errors\"].append({\"symbol\": sym, \"error\": last_err})\n",
    "\n",
    "        time.sleep(SLEEP_BETWEEN_TICKERS_SEC)\n",
    "\n",
    "    # ---- Metrics from CSV (no Yahoo fundamentals) ----\n",
    "    try:\n",
    "        funds = fetch_metrics_from_csv(\n",
    "            FUND_TICKERS,\n",
    "            CSV_METRICS_PATH,\n",
    "            sector_map=SECTOR_MAP\n",
    "        )\n",
    "    except Exception as e:\n",
    "        funds = {sym: {\"error\": f\"CSV read failed: {e}\", \"sector\": SECTOR_MAP.get(sym)} for sym in FUND_TICKERS}\n",
    "\n",
    "    funds_run_path = os.path.join(run_dir, \"fundamentals.json\")\n",
    "    funds_cur_path = os.path.join(current_dir, \"fundamentals.json\")\n",
    "    write_json(funds_run_path, funds)\n",
    "    write_json(funds_cur_path, funds)\n",
    "\n",
    "    run_summary[\"fundamentals\"] = {\n",
    "        \"tickers\": FUND_TICKERS,\n",
    "        \"file_run\": funds_run_path,\n",
    "        \"file_current\": funds_cur_path,\n",
    "        \"source\": \"csv\",\n",
    "        \"csv_path\": CSV_METRICS_PATH,\n",
    "        \"fields\": [\"marketcap\", \"pb_current\", \"pb_current_pctile\", \"div_y\"]\n",
    "    }\n",
    "\n",
    "    # ---- Save summary ----\n",
    "    write_json(os.path.join(run_dir, \"summary.json\"), run_summary)\n",
    "    write_json(os.path.join(current_dir, \"summary.json\"), run_summary)\n",
    "\n",
    "    # ---- Auto-commit & push ----\n",
    "    git_commit_and_push(\n",
    "        repo_root=base_dir,\n",
    "        run_dir=run_dir,\n",
    "        current_dir=current_dir,\n",
    "        branch=\"main\"\n",
    "    )\n",
    "\n",
    "    print(\"üèÅ Done.\")\n",
    "    if run_summary[\"errors\"]:\n",
    "        print(\"Some symbols failed (see summary.json).\")\n",
    "    else:\n",
    "        print(\"All symbols fetched successfully.\")\n",
    "    print(f\"Latest 'current' folder ready for Qualtrics: {current_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203b00c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1675a264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Daily archive folder: /Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Programming/Git/pilot3-asset-data/runs/run_2025-08-19\n",
      "üìÇ Current folder for Qualtrics: /Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Programming/Git/pilot3-asset-data/current_day2\n",
      "‚è≥ Fetching 365-day data for BTC-USD‚Ä¶\n",
      " ‚úÖ Wrote btc_365d.json (365 points)\n",
      "‚è≥ Fetching 365-day data for ETH-USD‚Ä¶\n",
      " ‚úÖ Wrote eth_365d.json (365 points)\n",
      "‚è≥ Fetching 365-day data for XMR-USD‚Ä¶\n",
      " ‚úÖ Wrote xmr_365d.json (365 points)\n",
      "‚è≥ Fetching 365-day data for APT21794-USD‚Ä¶\n",
      " ‚úÖ Wrote apt21794_365d.json (365 points)\n",
      "‚è≥ Fetching 365-day data for QNT-USD‚Ä¶\n",
      " ‚úÖ Wrote qnt_365d.json (365 points)\n",
      "‚è≥ Fetching 365-day data for TON11419-USD‚Ä¶\n",
      " ‚úÖ Wrote ton11419_365d.json (365 points)\n",
      "‚è≥ Fetching 365-day data for DOT-USD‚Ä¶\n",
      " ‚úÖ Wrote dot_365d.json (365 points)\n",
      "‚è≥ Fetching fundamentals for DOCN‚Ä¶\n",
      "‚è≥ Fetching fundamentals for MSFT‚Ä¶\n",
      "‚è≥ Fetching fundamentals for VZ‚Ä¶\n",
      "‚è≥ Fetching fundamentals for ZS‚Ä¶\n",
      "‚è≥ Fetching fundamentals for UFPI‚Ä¶\n",
      "‚è≥ Fetching fundamentals for DY‚Ä¶\n",
      "paul.grass@uni-bonn.de\n",
      "pagrass\n",
      "‚úÖ Pushed to origin; GitHub Action will purge jsDelivr cache.\n",
      "üèÅ Done.\n",
      "All symbols fetched successfully.\n",
      "Latest 'current' folder ready for Qualtrics: /Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Programming/Git/pilot3-asset-data/current_day2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To github.com:pagrass/pilot1-asset-data.git\n",
      "   79058b4..ba00fc3  main -> main\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import subprocess\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Deps: pip install yfinance curl_cffi\n",
    "from curl_cffi import requests\n",
    "import yfinance as yf\n",
    "\n",
    "# -------------------- Config --------------------\n",
    "\n",
    "# Stocks & cryptos\n",
    "STOCKS  = [\"CSCO\", \"TMUS\", \"TWLO\", \"PEGA\", \"ROG\", \"PD\"]\n",
    "\n",
    "#CRYPTOS = [\"BTC-USD\", \"ETH-USD\", \"XMR-USD\", \"APT21794-USD\", \"QNT-USD\", \"TON11419-USD\", \"DOT-USD\"]\n",
    "TICKERS = STOCKS \n",
    "#+ CRYPTOS\n",
    "\n",
    "FUND_TICKERS = [\"CSCO\", \"TMUS\", \"TWLO\", \"PEGA\", \"ROG\", \"PD\"]\n",
    "\n",
    "SECTOR_MAP = {\n",
    "    \"CSCO\": \"Information Technology\",\n",
    "    \"TMUS\": \"Communication Services\",\n",
    "    \"TWLO\": \"Information Technology\",\n",
    "    \"PEGA\": \"Information Technology\",\n",
    "    \"ROG\": \"Information Technology\",\n",
    "    \"PD\": \"Information Technologys\",\n",
    "}\n",
    "\n",
    "# Date window\n",
    "END   = datetime.now()\n",
    "START = END - timedelta(days=365)\n",
    "\n",
    "# Default base dir (each run gets a new subfolder here)\n",
    "DEFAULT_BASE_DIR = \"/Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Programming/Git/pilot4-asset-data\"\n",
    "\n",
    "\n",
    "# Rate limiting\n",
    "SLEEP_BETWEEN_TICKERS_SEC = 10\n",
    "MAX_RETRIES = 3\n",
    "RETRY_DELAY_SEC = 5\n",
    "\n",
    "# Safety: never allow writing into these substrings\n",
    "FORBIDDEN_SUBSTRINGS = [\"pilot3-asset-data\"]\n",
    "\n",
    "# -------------------- Helpers --------------------\n",
    "\n",
    "def git_commit_and_push(repo_root: str, run_dir: str, current_dir: str, branch: str = \"main\"):\n",
    "    # Only commit if there are changes in current/ or today's run folder\n",
    "    rel_run = os.path.relpath(run_dir, repo_root)\n",
    "    rel_cur = os.path.relpath(current_dir, repo_root)\n",
    "\n",
    "    # Make sure we're in the repo root so git paths work\n",
    "    cwd_before = os.getcwd()\n",
    "    os.chdir(repo_root)\n",
    "    try:\n",
    "        # Check if there are changes to these paths\n",
    "        diff = subprocess.run(\n",
    "            [\"git\", \"status\", \"--porcelain\", rel_cur, rel_run],\n",
    "            capture_output=True, text=True\n",
    "        )\n",
    "        if diff.returncode != 0:\n",
    "            print(\"‚ö†Ô∏è  git status failed; not pushing.\")\n",
    "            return\n",
    "        if diff.stdout.strip() == \"\":\n",
    "            print(\"‚ÑπÔ∏è  No changes to commit; skipping push.\")\n",
    "            return\n",
    "\n",
    "        # Ensure basic identity is set (won't override if already set)\n",
    "        subprocess.run([\"git\", \"config\", \"--get\", \"user.email\"], check=False)\n",
    "        subprocess.run([\"git\", \"config\", \"--get\", \"user.name\"], check=False)\n",
    "\n",
    "        # Stage just what we care about\n",
    "        subprocess.run([\"git\", \"add\", rel_cur, rel_run], check=True)\n",
    "\n",
    "        # Commit\n",
    "        msg = f\"Update data: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "        commit = subprocess.run([\"git\", \"commit\", \"-m\", msg], capture_output=True, text=True)\n",
    "        if commit.returncode != 0:\n",
    "            # Likely \"nothing to commit\" race; bail quietly\n",
    "            print(commit.stdout or commit.stderr or \"‚ÑπÔ∏è  Nothing to commit.\")\n",
    "            return\n",
    "\n",
    "        # Push\n",
    "        subprocess.run([\"git\", \"push\", \"origin\", branch], check=True)\n",
    "        print(\"‚úÖ Pushed to origin; GitHub Action will purge jsDelivr cache.\")\n",
    "    finally:\n",
    "        os.chdir(cwd_before)\n",
    "\n",
    "def fetch_fundamentals(symbols, yf_session, max_retries=3, retry_delay=5):\n",
    "    \"\"\"\n",
    "    Returns a dict {SYM: {eps, pe, div_y, sector}}.\n",
    "    Uses yfinance .info (can be slow/flaky; retried for robustness).\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    for sym in symbols:\n",
    "        print(f\"‚è≥ Fetching fundamentals for {sym}‚Ä¶\")\n",
    "        last_err = None\n",
    "        for attempt in range(1, max_retries + 1):\n",
    "            try:\n",
    "                t = yf.Ticker(sym, session=yf_session)\n",
    "                info = t.info  # may be slow / rate-limited\n",
    "                eps = info.get(\"trailingEps\")\n",
    "                price = info.get(\"regularMarketPrice\")\n",
    "                pe = round(price / eps, 1) if eps and price else None\n",
    "                dy = info.get(\"dividendYield\")\n",
    "                if dy is not None:\n",
    "                    dy = round(dy * 100, 1)\n",
    "                out[sym] = {\n",
    "                    \"eps\": eps,\n",
    "                    \"pe\": pe,\n",
    "                    \"div_y\": dy,\n",
    "                    \"sector\": SECTOR_MAP.get(sym),\n",
    "                }\n",
    "                last_err = None\n",
    "                break\n",
    "            except Exception as e:\n",
    "                last_err = str(e)\n",
    "                print(f\"   ‚ö†Ô∏è  Attempt {attempt}/{max_retries} failed: {last_err}\")\n",
    "                if attempt < max_retries:\n",
    "                    time.sleep(retry_delay)\n",
    "        if last_err:\n",
    "            # record partial error so you see it in summary.json\n",
    "            out[sym] = {\"error\": last_err, \"sector\": SECTOR_MAP.get(sym)}\n",
    "        time.sleep(2)  # small spacing to be polite\n",
    "    return out\n",
    "\n",
    "\n",
    "def guard_path(path: str):\n",
    "    norm = os.path.normpath(path)\n",
    "    for bad in FORBIDDEN_SUBSTRINGS:\n",
    "        if bad in norm:\n",
    "            raise RuntimeError(f\"Refusing to write into forbidden path: {norm}\")\n",
    "\n",
    "def safe_mkdirs(path: str):\n",
    "    guard_path(path)\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "def make_daily_run_dir(base_dir: str) -> str:\n",
    "    date_str = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    run_dir = os.path.join(base_dir, \"runs\", f\"run_{date_str}\")\n",
    "    safe_mkdirs(run_dir)\n",
    "    return run_dir\n",
    "\n",
    "\n",
    "def ensure_current_dir(base_dir: str) -> str:\n",
    "    # Put current/ directly under base_dir (not inside runs/)\n",
    "    cur = os.path.join(base_dir, \"current_day2\")\n",
    "    safe_mkdirs(cur)\n",
    "    return cur\n",
    "\n",
    "def copy_to_current(src_path: str, current_dir: str):\n",
    "    guard_path(current_dir)\n",
    "    dst_path = os.path.join(current_dir, os.path.basename(src_path))\n",
    "    with open(src_path, \"rb\") as s, open(dst_path, \"wb\") as d:\n",
    "        d.write(s.read())\n",
    "    return dst_path\n",
    "\n",
    "\n",
    "\n",
    "def write_json(path: str, obj):\n",
    "    guard_path(path)\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(obj, f, indent=2)\n",
    "\n",
    "def create_or_update_symlink(target_dir: str, link_path: str):\n",
    "    # Create/refresh a 'latest' symlink for convenience (best-effort)\n",
    "    try:\n",
    "        if os.path.islink(link_path) or os.path.exists(link_path):\n",
    "            os.remove(link_path)\n",
    "        os.symlink(target_dir, link_path)\n",
    "    except Exception:\n",
    "        # Non-fatal if symlink fails (e.g., on certain filesystems)\n",
    "        pass\n",
    "\n",
    "# -------------------- Main --------------------\n",
    "\n",
    "def main():\n",
    "    session = requests.Session(impersonate=\"chrome124\")\n",
    "    yf_session = session  # yfinance accepts a curl_cffi session via 'session'\n",
    "\n",
    "    base_dir = os.getenv(\"DATA_BASE_DIR\", DEFAULT_BASE_DIR)\n",
    "    guard_path(base_dir)\n",
    "    safe_mkdirs(base_dir)\n",
    "\n",
    "    run_dir = make_daily_run_dir(base_dir)\n",
    "    current_dir = ensure_current_dir(base_dir)\n",
    "\n",
    "    print(f\"üìÅ Daily archive folder: {run_dir}\")\n",
    "    print(f\"üìÇ Current folder for Qualtrics: {current_dir}\")\n",
    "\n",
    "    run_summary = {\n",
    "        \"started_at\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "        \"window_start\": START.strftime(\"%Y-%m-%d\"),\n",
    "        \"window_end\": END.strftime(\"%Y-%m-%d\"),\n",
    "        \"files\": [],\n",
    "        \"errors\": [],\n",
    "    }\n",
    "\n",
    "    for sym in TICKERS:\n",
    "        print(f\"‚è≥ Fetching 365-day data for {sym}‚Ä¶\")\n",
    "        last_err = None\n",
    "        for attempt in range(1, MAX_RETRIES + 1):\n",
    "            try:\n",
    "                tkr = yf.Ticker(sym, session=yf_session)\n",
    "                df = tkr.history(\n",
    "                    start=START.strftime(\"%Y-%m-%d\"),\n",
    "                    end=END.strftime(\"%Y-%m-%d\"),\n",
    "                    auto_adjust=True,\n",
    "                )\n",
    "                if df is None or df.empty:\n",
    "                    raise ValueError(\"Empty dataframe returned.\")\n",
    "\n",
    "                pts = [\n",
    "                    [int(row_ts.timestamp() * 1000), round(float(row[\"Close\"]), 2)]\n",
    "                    for row_ts, row in df.iterrows()\n",
    "                    if row.get(\"Close\") is not None\n",
    "                ]\n",
    "                if not pts:\n",
    "                    raise ValueError(\"No valid close prices found.\")\n",
    "\n",
    "                out_sym = sym.replace(\"-USD\", \"\").replace(\".\", \"\").lower()\n",
    "\n",
    "                # Write to daily run folder\n",
    "                out_path = os.path.join(run_dir, f\"{out_sym}_365d.json\")\n",
    "                write_json(out_path, {\"prices\": pts})\n",
    "\n",
    "                # Also copy to current folder for Qualtrics\n",
    "                copy_to_current(out_path, current_dir)\n",
    "\n",
    "                print(f\" ‚úÖ Wrote {out_sym}_365d.json ({len(pts)} points)\")\n",
    "\n",
    "                run_summary[\"files\"].append({\n",
    "                    \"symbol\": sym,\n",
    "                    \"file\": out_path,\n",
    "                    \"points\": len(pts),\n",
    "                    \"first_ts\": pts[0][0],\n",
    "                    \"last_ts\": pts[-1][0],\n",
    "                })\n",
    "                last_err = None\n",
    "                break\n",
    "            except Exception as e:\n",
    "                last_err = str(e)\n",
    "                print(f\"   ‚ö†Ô∏è Attempt {attempt}/{MAX_RETRIES} failed: {last_err}\")\n",
    "                if attempt < MAX_RETRIES:\n",
    "                    time.sleep(RETRY_DELAY_SEC)\n",
    "\n",
    "        if last_err:\n",
    "            run_summary[\"errors\"].append({\"symbol\": sym, \"error\": last_err})\n",
    "\n",
    "        time.sleep(SLEEP_BETWEEN_TICKERS_SEC)\n",
    "    # --- fundamentals ---\n",
    "    funds = fetch_fundamentals(FUND_TICKERS, yf_session, max_retries=MAX_RETRIES, retry_delay=RETRY_DELAY_SEC)\n",
    "\n",
    "    # save fundamentals.json in both places\n",
    "    funds_run_path = os.path.join(run_dir, \"fundamentals.json\")\n",
    "    funds_cur_path = os.path.join(current_dir, \"fundamentals.json\")\n",
    "    write_json(funds_run_path, funds)\n",
    "    write_json(funds_cur_path, funds)\n",
    "\n",
    "    # add to summary\n",
    "    run_summary[\"fundamentals\"] = {\n",
    "        \"tickers\": FUND_TICKERS,\n",
    "        \"file_run\": funds_run_path,\n",
    "        \"file_current\": funds_cur_path,\n",
    "    }\n",
    "\n",
    "    # Save summary to both locations\n",
    "    write_json(os.path.join(run_dir, \"summary.json\"), run_summary)\n",
    "    write_json(os.path.join(current_dir, \"summary.json\"), run_summary)\n",
    "\n",
    "    # Auto-commit & push (triggers purge workflow)\n",
    "    git_commit_and_push(\n",
    "        repo_root=base_dir,\n",
    "        run_dir=run_dir,\n",
    "        current_dir=current_dir,\n",
    "        branch=\"main\"\n",
    "    )\n",
    "\n",
    "\n",
    "    print(\"üèÅ Done.\")\n",
    "    if run_summary[\"errors\"]:\n",
    "        print(\"Some symbols failed (see summary.json).\")\n",
    "    else:\n",
    "        print(\"All symbols fetched successfully.\")\n",
    "    print(f\"Latest 'current' folder ready for Qualtrics: {current_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb8d686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Daily archive folder: /Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Programming/Git/pilot3-asset-data/runs/run_2025-10-20\n",
      "üìÇ Current folder for Qualtrics: /Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Programming/Git/pilot3-asset-data/current_day2\n",
      "‚è≥ Fetching 365-day data for CSCO‚Ä¶\n",
      " ‚úÖ Wrote csco_365d.json (249 points)\n",
      "‚è≥ Fetching 365-day data for MSFT‚Ä¶\n",
      " ‚úÖ Wrote msft_365d.json (249 points)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 293\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLatest \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrent\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m folder ready for Qualtrics: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 293\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[1], line 255\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m last_err:\n\u001b[1;32m    253\u001b[0m         run_summary[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrors\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msymbol\u001b[39m\u001b[38;5;124m\"\u001b[39m: sym, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m: last_err})\n\u001b[0;32m--> 255\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(SLEEP_BETWEEN_TICKERS_SEC)\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# --- fundamentals ---\u001b[39;00m\n\u001b[1;32m    257\u001b[0m funds \u001b[38;5;241m=\u001b[39m fetch_fundamentals(FUND_TICKERS, yf_session, max_retries\u001b[38;5;241m=\u001b[39mMAX_RETRIES, retry_delay\u001b[38;5;241m=\u001b[39mRETRY_DELAY_SEC)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import subprocess\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Deps: pip install yfinance curl_cffi\n",
    "from curl_cffi import requests\n",
    "import yfinance as yf\n",
    "\n",
    "# -------------------- Config --------------------\n",
    "\n",
    "# Stocks & cryptos\n",
    "STOCKS  = [\"CSCO\", \"ARLO\", \"CMPO\", \"ZS\", \"KO\", \"MCD\"]\n",
    "#STOCKS  = []\n",
    "\n",
    "#CRYPTOS = [\"BTC-USD\", \"ETH-USD\", \"XMR-USD\", \"APT21794-USD\", \"QNT-USD\", \"TON11419-USD\", \"DOT-USD\"]\n",
    "CRYPTOS = []\n",
    "TICKERS = STOCKS + CRYPTOS\n",
    "\n",
    "FUND_TICKERS = [\"DOCN\", \"ARLO\", \"CMPO\", \"ZS\", \"KO\", \"MCD\"]\n",
    "\n",
    "SECTOR_MAP = {\n",
    "    \"DOCN\": \"Technology\",\n",
    "    \"MSFT\": \"Technology\",\n",
    "    \"VZ\":  \"Communication Services\",\n",
    "    \"ZS\":  \"Technology\",\n",
    "    \"UFPI\": \"Basic Materials\",\n",
    "    \"DY\":   \"Industrials\",\n",
    "}\n",
    "\n",
    "# Date window\n",
    "END   = datetime.now()\n",
    "START = END - timedelta(days=365)\n",
    "\n",
    "# Default base dir (each run gets a new subfolder here)\n",
    "DEFAULT_BASE_DIR = \"/Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Programming/Git/pilot3-asset-data\"\n",
    "\n",
    "\n",
    "# Rate limiting\n",
    "SLEEP_BETWEEN_TICKERS_SEC = 10\n",
    "MAX_RETRIES = 3\n",
    "RETRY_DELAY_SEC = 5\n",
    "\n",
    "# Safety: never allow writing into these substrings\n",
    "FORBIDDEN_SUBSTRINGS = [\"pilot2-asset-data\"]\n",
    "\n",
    "# -------------------- Helpers --------------------\n",
    "\n",
    "def git_commit_and_push(repo_root: str, run_dir: str, current_dir: str, branch: str = \"main\"):\n",
    "    # Only commit if there are changes in current/ or today's run folder\n",
    "    rel_run = os.path.relpath(run_dir, repo_root)\n",
    "    rel_cur = os.path.relpath(current_dir, repo_root)\n",
    "\n",
    "    # Make sure we're in the repo root so git paths work\n",
    "    cwd_before = os.getcwd()\n",
    "    os.chdir(repo_root)\n",
    "    try:\n",
    "        # Check if there are changes to these paths\n",
    "        diff = subprocess.run(\n",
    "            [\"git\", \"status\", \"--porcelain\", rel_cur, rel_run],\n",
    "            capture_output=True, text=True\n",
    "        )\n",
    "        if diff.returncode != 0:\n",
    "            print(\"‚ö†Ô∏è  git status failed; not pushing.\")\n",
    "            return\n",
    "        if diff.stdout.strip() == \"\":\n",
    "            print(\"‚ÑπÔ∏è  No changes to commit; skipping push.\")\n",
    "            return\n",
    "\n",
    "        # Ensure basic identity is set (won't override if already set)\n",
    "        subprocess.run([\"git\", \"config\", \"--get\", \"user.email\"], check=False)\n",
    "        subprocess.run([\"git\", \"config\", \"--get\", \"user.name\"], check=False)\n",
    "\n",
    "        # Stage just what we care about\n",
    "        subprocess.run([\"git\", \"add\", rel_cur, rel_run], check=True)\n",
    "\n",
    "        # Commit\n",
    "        msg = f\"Update data: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "        commit = subprocess.run([\"git\", \"commit\", \"-m\", msg], capture_output=True, text=True)\n",
    "        if commit.returncode != 0:\n",
    "            # Likely \"nothing to commit\" race; bail quietly\n",
    "            print(commit.stdout or commit.stderr or \"‚ÑπÔ∏è  Nothing to commit.\")\n",
    "            return\n",
    "\n",
    "        # Push\n",
    "        subprocess.run([\"git\", \"push\", \"origin\", branch], check=True)\n",
    "        print(\"‚úÖ Pushed to origin; GitHub Action will purge jsDelivr cache.\")\n",
    "    finally:\n",
    "        os.chdir(cwd_before)\n",
    "\n",
    "def fetch_fundamentals(symbols, yf_session, max_retries=3, retry_delay=5):\n",
    "    \"\"\"\n",
    "    Returns a dict {SYM: {eps, pe, div_y, sector}}.\n",
    "    Uses yfinance .info (can be slow/flaky; retried for robustness).\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    for sym in symbols:\n",
    "        print(f\"‚è≥ Fetching fundamentals for {sym}‚Ä¶\")\n",
    "        last_err = None\n",
    "        for attempt in range(1, max_retries + 1):\n",
    "            try:\n",
    "                t = yf.Ticker(sym, session=yf_session)\n",
    "                info = t.info  # may be slow / rate-limited\n",
    "                eps = info.get(\"trailingEps\")\n",
    "                price = info.get(\"regularMarketPrice\")\n",
    "                pe = round(price / eps, 1) if eps and price else None\n",
    "                dy = info.get(\"dividendYield\")\n",
    "                if dy is not None:\n",
    "                    dy = round(dy * 100, 1)\n",
    "                out[sym] = {\n",
    "                    \"eps\": eps,\n",
    "                    \"pe\": pe,\n",
    "                    \"div_y\": dy,\n",
    "                    \"sector\": SECTOR_MAP.get(sym),\n",
    "                }\n",
    "                last_err = None\n",
    "                break\n",
    "            except Exception as e:\n",
    "                last_err = str(e)\n",
    "                print(f\"   ‚ö†Ô∏è  Attempt {attempt}/{max_retries} failed: {last_err}\")\n",
    "                if attempt < max_retries:\n",
    "                    time.sleep(retry_delay)\n",
    "        if last_err:\n",
    "            # record partial error so you see it in summary.json\n",
    "            out[sym] = {\"error\": last_err, \"sector\": SECTOR_MAP.get(sym)}\n",
    "        time.sleep(2)  # small spacing to be polite\n",
    "    return out\n",
    "\n",
    "\n",
    "def guard_path(path: str):\n",
    "    norm = os.path.normpath(path)\n",
    "    for bad in FORBIDDEN_SUBSTRINGS:\n",
    "        if bad in norm:\n",
    "            raise RuntimeError(f\"Refusing to write into forbidden path: {norm}\")\n",
    "\n",
    "def safe_mkdirs(path: str):\n",
    "    guard_path(path)\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "def make_daily_run_dir(base_dir: str) -> str:\n",
    "    date_str = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    run_dir = os.path.join(base_dir, \"runs\", f\"run_{date_str}\")\n",
    "    safe_mkdirs(run_dir)\n",
    "    return run_dir\n",
    "\n",
    "\n",
    "def ensure_current_dir(base_dir: str) -> str:\n",
    "    # Put current/ directly under base_dir (not inside runs/)\n",
    "    cur = os.path.join(base_dir, \"current_day2\")\n",
    "    safe_mkdirs(cur)\n",
    "    return cur\n",
    "\n",
    "def copy_to_current(src_path: str, current_dir: str):\n",
    "    guard_path(current_dir)\n",
    "    dst_path = os.path.join(current_dir, os.path.basename(src_path))\n",
    "    with open(src_path, \"rb\") as s, open(dst_path, \"wb\") as d:\n",
    "        d.write(s.read())\n",
    "    return dst_path\n",
    "\n",
    "\n",
    "\n",
    "def write_json(path: str, obj):\n",
    "    guard_path(path)\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(obj, f, indent=2)\n",
    "\n",
    "def create_or_update_symlink(target_dir: str, link_path: str):\n",
    "    # Create/refresh a 'latest' symlink for convenience (best-effort)\n",
    "    try:\n",
    "        if os.path.islink(link_path) or os.path.exists(link_path):\n",
    "            os.remove(link_path)\n",
    "        os.symlink(target_dir, link_path)\n",
    "    except Exception:\n",
    "        # Non-fatal if symlink fails (e.g., on certain filesystems)\n",
    "        pass\n",
    "\n",
    "# -------------------- Main --------------------\n",
    "\n",
    "def main():\n",
    "    session = requests.Session(impersonate=\"chrome124\")\n",
    "    yf_session = session  # yfinance accepts a curl_cffi session via 'session'\n",
    "\n",
    "    base_dir = os.getenv(\"DATA_BASE_DIR\", DEFAULT_BASE_DIR)\n",
    "    guard_path(base_dir)\n",
    "    safe_mkdirs(base_dir)\n",
    "\n",
    "    run_dir = make_daily_run_dir(base_dir)\n",
    "    current_dir = ensure_current_dir(base_dir)\n",
    "\n",
    "    print(f\"üìÅ Daily archive folder: {run_dir}\")\n",
    "    print(f\"üìÇ Current folder for Qualtrics: {current_dir}\")\n",
    "\n",
    "    run_summary = {\n",
    "        \"started_at\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "        \"window_start\": START.strftime(\"%Y-%m-%d\"),\n",
    "        \"window_end\": END.strftime(\"%Y-%m-%d\"),\n",
    "        \"files\": [],\n",
    "        \"errors\": [],\n",
    "    }\n",
    "\n",
    "    for sym in TICKERS:\n",
    "        print(f\"‚è≥ Fetching 365-day data for {sym}‚Ä¶\")\n",
    "        last_err = None\n",
    "        for attempt in range(1, MAX_RETRIES + 1):\n",
    "            try:\n",
    "                tkr = yf.Ticker(sym, session=yf_session)\n",
    "                df = tkr.history(\n",
    "                    start=START.strftime(\"%Y-%m-%d\"),\n",
    "                    end=END.strftime(\"%Y-%m-%d\"),\n",
    "                    auto_adjust=True,\n",
    "                )\n",
    "                if df is None or df.empty:\n",
    "                    raise ValueError(\"Empty dataframe returned.\")\n",
    "\n",
    "                pts = [\n",
    "                    [int(row_ts.timestamp() * 1000), round(float(row[\"Close\"]), 2)]\n",
    "                    for row_ts, row in df.iterrows()\n",
    "                    if row.get(\"Close\") is not None\n",
    "                ]\n",
    "                if not pts:\n",
    "                    raise ValueError(\"No valid close prices found.\")\n",
    "\n",
    "                out_sym = sym.replace(\"-USD\", \"\").replace(\".\", \"\").lower()\n",
    "\n",
    "                # Write to daily run folder\n",
    "                out_path = os.path.join(run_dir, f\"{out_sym}_365d.json\")\n",
    "                write_json(out_path, {\"prices\": pts})\n",
    "\n",
    "                # Also copy to current folder for Qualtrics\n",
    "                copy_to_current(out_path, current_dir)\n",
    "\n",
    "                print(f\" ‚úÖ Wrote {out_sym}_365d.json ({len(pts)} points)\")\n",
    "\n",
    "                run_summary[\"files\"].append({\n",
    "                    \"symbol\": sym,\n",
    "                    \"file\": out_path,\n",
    "                    \"points\": len(pts),\n",
    "                    \"first_ts\": pts[0][0],\n",
    "                    \"last_ts\": pts[-1][0],\n",
    "                })\n",
    "                last_err = None\n",
    "                break\n",
    "            except Exception as e:\n",
    "                last_err = str(e)\n",
    "                print(f\"   ‚ö†Ô∏è Attempt {attempt}/{MAX_RETRIES} failed: {last_err}\")\n",
    "                if attempt < MAX_RETRIES:\n",
    "                    time.sleep(RETRY_DELAY_SEC)\n",
    "\n",
    "        if last_err:\n",
    "            run_summary[\"errors\"].append({\"symbol\": sym, \"error\": last_err})\n",
    "\n",
    "        time.sleep(SLEEP_BETWEEN_TICKERS_SEC)\n",
    "    # --- fundamentals ---\n",
    "    funds = fetch_fundamentals(FUND_TICKERS, yf_session, max_retries=MAX_RETRIES, retry_delay=RETRY_DELAY_SEC)\n",
    "\n",
    "    # save fundamentals.json in both places\n",
    "    funds_run_path = os.path.join(run_dir, \"fundamentals.json\")\n",
    "    funds_cur_path = os.path.join(current_dir, \"fundamentals.json\")\n",
    "    write_json(funds_run_path, funds)\n",
    "    write_json(funds_cur_path, funds)\n",
    "\n",
    "    # add to summary\n",
    "    run_summary[\"fundamentals\"] = {\n",
    "        \"tickers\": FUND_TICKERS,\n",
    "        \"file_run\": funds_run_path,\n",
    "        \"file_current\": funds_cur_path,\n",
    "    }\n",
    "\n",
    "    # Save summary to both locations\n",
    "    write_json(os.path.join(run_dir, \"summary.json\"), run_summary)\n",
    "    write_json(os.path.join(current_dir, \"summary.json\"), run_summary)\n",
    "\n",
    "    # Auto-commit & push (triggers purge workflow)\n",
    "    git_commit_and_push(\n",
    "        repo_root=base_dir,\n",
    "        run_dir=run_dir,\n",
    "        current_dir=current_dir,\n",
    "        branch=\"main\"\n",
    "    )\n",
    "\n",
    "\n",
    "    print(\"üèÅ Done.\")\n",
    "    if run_summary[\"errors\"]:\n",
    "        print(\"Some symbols failed (see summary.json).\")\n",
    "    else:\n",
    "        print(\"All symbols fetched successfully.\")\n",
    "    print(f\"Latest 'current' folder ready for Qualtrics: {current_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mech-coding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
