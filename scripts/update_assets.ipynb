{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473e2f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Daily archive folder: /Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Programming/Git/pilot3-asset-data/runs/run_2025-10-21\n",
      "📂 Current folder for Qualtrics: /Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Programming/Git/pilot3-asset-data/current_day2\n",
      "⏳ Fetching 365-day data for CSCO…\n",
      " ✅ Wrote csco_365d.json (250 points)\n",
      "⏳ Fetching 365-day data for TMUS…\n",
      " ✅ Wrote tmus_365d.json (250 points)\n",
      "⏳ Fetching 365-day data for TWLO…\n",
      " ✅ Wrote twlo_365d.json (250 points)\n",
      "⏳ Fetching 365-day data for PEGA…\n",
      " ✅ Wrote pega_365d.json (250 points)\n",
      "⏳ Fetching 365-day data for ROG…\n",
      " ✅ Wrote rog_365d.json (250 points)\n",
      "⏳ Fetching 365-day data for PD…\n",
      " ✅ Wrote pd_365d.json (250 points)\n",
      "✅ Pushed to origin; GitHub Action will purge jsDelivr cache.\n",
      "🏁 Done.\n",
      "All symbols fetched successfully.\n",
      "Latest 'current' folder ready for Qualtrics: /Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Programming/Git/pilot3-asset-data/current_day2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To github.com:pagrass/pilot1-asset-data.git\n",
      "   2594ed8..5f50daa  main -> main\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import csv\n",
    "import subprocess\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Deps: pip install yfinance\n",
    "import yfinance as yf\n",
    "\n",
    "# -------------------- Config --------------------\n",
    "\n",
    "# Stocks\n",
    "STOCKS  = [\"CSCO\", \"TMUS\", \"TWLO\", \"PEGA\", \"ROG\", \"PD\"]\n",
    "TICKERS = STOCKS\n",
    "\n",
    "FUND_TICKERS = [\"CSCO\", \"TMUS\", \"TWLO\", \"PEGA\", \"ROG\", \"PD\"]\n",
    "\n",
    "SECTOR_MAP = {\n",
    "    \"CSCO\": \"Information Technology\",\n",
    "    \"TMUS\": \"Communication Services\",\n",
    "    \"TWLO\": \"Information Technology\",\n",
    "    \"PEGA\": \"Information Technology\",\n",
    "    \"ROG\":  \"Information Technology\",\n",
    "    \"PD\":   \"Information Technology\",\n",
    "}\n",
    "\n",
    "# Date window\n",
    "END   = datetime.now()\n",
    "START = END - timedelta(days=365)\n",
    "\n",
    "# Default base dir (each run gets a new subfolder here)\n",
    "DEFAULT_BASE_DIR = \"/Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Programming/Git/pilot3-asset-data\"\n",
    "\n",
    "# Path to CSV “dictionary”\n",
    "CSV_METRICS_PATH = \"/Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Model Spillovers/Data/Stock Selection/preselection/candidate_subset_all.csv\"\n",
    "\n",
    "# Rate limiting\n",
    "SLEEP_BETWEEN_TICKERS_SEC = 10\n",
    "MAX_RETRIES = 3\n",
    "RETRY_DELAY_SEC = 5\n",
    "\n",
    "# Safety: never allow writing into these substrings\n",
    "FORBIDDEN_SUBSTRINGS = [\"pilot2-asset-data\"]\n",
    "\n",
    "# -------------------- Helpers --------------------\n",
    "\n",
    "def git_commit_and_push(repo_root: str, run_dir: str, current_dir: str, branch: str = \"main\"):\n",
    "    # Only commit if there are changes in current/ or today's run folder\n",
    "    rel_run = os.path.relpath(run_dir, repo_root)\n",
    "    rel_cur = os.path.relpath(current_dir, repo_root)\n",
    "\n",
    "    cwd_before = os.getcwd()\n",
    "    os.chdir(repo_root)\n",
    "    try:\n",
    "        diff = subprocess.run(\n",
    "            [\"git\", \"status\", \"--porcelain\", rel_cur, rel_run],\n",
    "            capture_output=True, text=True\n",
    "        )\n",
    "        if diff.returncode != 0:\n",
    "            print(\"⚠️  git status failed; not pushing.\")\n",
    "            return\n",
    "        if diff.stdout.strip() == \"\":\n",
    "            print(\"ℹ️  No changes to commit; skipping push.\")\n",
    "            return\n",
    "\n",
    "        # Stage just what we care about\n",
    "        subprocess.run([\"git\", \"add\", rel_cur, rel_run], check=True)\n",
    "\n",
    "        # Commit\n",
    "        msg = f\"Update data: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "        commit = subprocess.run([\"git\", \"commit\", \"-m\", msg], capture_output=True, text=True)\n",
    "        if commit.returncode != 0:\n",
    "            print(commit.stdout or commit.stderr or \"ℹ️  Nothing to commit.\")\n",
    "            return\n",
    "\n",
    "        # Push\n",
    "        subprocess.run([\"git\", \"push\", \"origin\", branch], check=True)\n",
    "        print(\"✅ Pushed to origin; GitHub Action will purge jsDelivr cache.\")\n",
    "    finally:\n",
    "        os.chdir(cwd_before)\n",
    "\n",
    "def guard_path(path: str):\n",
    "    norm = os.path.normpath(path)\n",
    "    for bad in FORBIDDEN_SUBSTRINGS:\n",
    "        if bad in norm:\n",
    "            raise RuntimeError(f\"Refusing to write into forbidden path: {norm}\")\n",
    "\n",
    "def safe_mkdirs(path: str):\n",
    "    guard_path(path)\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "def make_daily_run_dir(base_dir: str) -> str:\n",
    "    date_str = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    run_dir = os.path.join(base_dir, \"runs\", f\"run_{date_str}\")\n",
    "    safe_mkdirs(run_dir)\n",
    "    return run_dir\n",
    "\n",
    "def ensure_current_dir(base_dir: str) -> str:\n",
    "    cur = os.path.join(base_dir, \"current_day2\")\n",
    "    safe_mkdirs(cur)\n",
    "    return cur\n",
    "\n",
    "def copy_to_current(src_path: str, current_dir: str):\n",
    "    guard_path(current_dir)\n",
    "    dst_path = os.path.join(current_dir, os.path.basename(src_path))\n",
    "    with open(src_path, \"rb\") as s, open(dst_path, \"wb\") as d:\n",
    "        d.write(s.read())\n",
    "    return dst_path\n",
    "\n",
    "def write_json(path: str, obj):\n",
    "    guard_path(path)\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(obj, f, indent=2)\n",
    "\n",
    "# ---------- CSV metrics ----------\n",
    "\n",
    "def _coerce_number(val):\n",
    "    \"\"\"Coerce CSV field to float if possible; return None for empty/invalid.\"\"\"\n",
    "    if val is None:\n",
    "        return None\n",
    "    s = str(val).strip()\n",
    "    if s == \"\" or s.lower() in {\"na\", \"nan\", \"none\"}:\n",
    "        return None\n",
    "    try:\n",
    "        return float(s.replace(\",\", \"\"))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def fetch_metrics_from_csv(symbols, csv_path, sector_map=None):\n",
    "    \"\"\"\n",
    "    Pull marketcap, pb_current, pb_current_pctile, div_y from a CSV keyed by ticker.\n",
    "\n",
    "    Post-processing:\n",
    "      - marketcap -> divide by 1,000,000 and round to 2 decimals (millions)\n",
    "      - pb_current_pctile -> round to 2 decimals\n",
    "      - div_y (aka div_yield/dividend_yield) -> divide by 100 (to decimal)\n",
    "      - valuation (new): Low / Mid / High based on pb_current_pctile\n",
    "    \"\"\"\n",
    "    lookup = {}\n",
    "    with open(csv_path, newline=\"\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            row_lower = {k.lower(): v for k, v in row.items()}\n",
    "            tk = (row_lower.get(\"ticker\") or row_lower.get(\"symbol\") or \"\").strip().upper()\n",
    "            if tk:\n",
    "                lookup[tk] = row_lower\n",
    "\n",
    "    out = {}\n",
    "    for sym in symbols:\n",
    "        key = sym.upper()\n",
    "        row = lookup.get(key)\n",
    "        if not row:\n",
    "            out[key] = {\"error\": \"Ticker not found in CSV\", \"sector\": (sector_map or {}).get(key)}\n",
    "            continue\n",
    "\n",
    "        mc_raw = _coerce_number(row.get(\"marketcap\"))\n",
    "        pb = _coerce_number(row.get(\"pb_current\"))\n",
    "        pb_pct_raw = _coerce_number(row.get(\"pb_current_pctile\"))\n",
    "\n",
    "        # Flexible dividend yield column handling\n",
    "        div_candidates = [\"div_y\", \"div_yield\", \"dividend_yield\"]\n",
    "        div_raw = None\n",
    "        for c in div_candidates:\n",
    "            if c in row:\n",
    "                div_raw = _coerce_number(row.get(c))\n",
    "                if div_raw is not None:\n",
    "                    break\n",
    "\n",
    "        # ---- Post-processing transforms ----\n",
    "        mc_millions = round(mc_raw / 1_000_000_000, 2) if mc_raw is not None else None\n",
    "        pb_pct = round(pb_pct_raw * 100, 0) if pb_pct_raw is not None else None\n",
    "        div_val = (div_raw) if div_raw is not None else None\n",
    "\n",
    "        # ---- Valuation classification ----\n",
    "        if pb_pct is None:\n",
    "            valuation = None\n",
    "        elif pb_pct < 0.33:\n",
    "            valuation = \"Low\"\n",
    "        elif pb_pct < 0.67:\n",
    "            valuation = \"Mid\"\n",
    "        else:\n",
    "            valuation = \"High\"\n",
    "\n",
    "        out[key] = {\n",
    "            \"marketcap\": mc_millions,\n",
    "            \"pb_current\": pb,\n",
    "            \"pb_current_pctile\": pb_pct,\n",
    "            \"div_y\": div_val,\n",
    "            \"valuation\": valuation,   # 👈 new field\n",
    "        }\n",
    "        if sector_map:\n",
    "            out[key][\"sector\"] = sector_map.get(key)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# -------------------- Main --------------------\n",
    "\n",
    "def main():\n",
    "    base_dir = os.getenv(\"DATA_BASE_DIR\", DEFAULT_BASE_DIR)\n",
    "    guard_path(base_dir)\n",
    "    safe_mkdirs(base_dir)\n",
    "\n",
    "    run_dir = make_daily_run_dir(base_dir)\n",
    "    current_dir = ensure_current_dir(base_dir)\n",
    "\n",
    "    print(f\"📁 Daily archive folder: {run_dir}\")\n",
    "    print(f\"📂 Current folder for Qualtrics: {current_dir}\")\n",
    "\n",
    "    run_summary = {\n",
    "        \"started_at\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "        \"window_start\": START.strftime(\"%Y-%m-%d\"),\n",
    "        \"window_end\": END.strftime(\"%Y-%m-%d\"),\n",
    "        \"files\": [],\n",
    "        \"errors\": [],\n",
    "    }\n",
    "\n",
    "    # ---- Price history (yfinance) ----\n",
    "    for sym in TICKERS:\n",
    "        print(f\"⏳ Fetching 365-day data for {sym}…\")\n",
    "        last_err = None\n",
    "        for attempt in range(1, MAX_RETRIES + 1):\n",
    "            try:\n",
    "                tkr = yf.Ticker(sym)\n",
    "                df = tkr.history(\n",
    "                    start=START.strftime(\"%Y-%m-%d\"),\n",
    "                    end=END.strftime(\"%Y-%m-%d\"),\n",
    "                    auto_adjust=True,\n",
    "                )\n",
    "                if df is None or df.empty:\n",
    "                    raise ValueError(\"Empty dataframe returned.\")\n",
    "\n",
    "                pts = [\n",
    "                    [int(row_ts.timestamp() * 1000), round(float(row[\"Close\"]), 2)]\n",
    "                    for row_ts, row in df.iterrows()\n",
    "                    if row.get(\"Close\") is not None\n",
    "                ]\n",
    "                if not pts:\n",
    "                    raise ValueError(\"No valid close prices found.\")\n",
    "\n",
    "                out_sym = sym.replace(\"-USD\", \"\").replace(\".\", \"\").lower()\n",
    "\n",
    "                out_path = os.path.join(run_dir, f\"{out_sym}_365d.json\")\n",
    "                write_json(out_path, {\"prices\": pts})\n",
    "\n",
    "                copy_to_current(out_path, current_dir)\n",
    "\n",
    "                print(f\" ✅ Wrote {out_sym}_365d.json ({len(pts)} points)\")\n",
    "\n",
    "                run_summary[\"files\"].append({\n",
    "                    \"symbol\": sym,\n",
    "                    \"file\": out_path,\n",
    "                    \"points\": len(pts),\n",
    "                    \"first_ts\": pts[0][0],\n",
    "                    \"last_ts\": pts[-1][0],\n",
    "                })\n",
    "                last_err = None\n",
    "                break\n",
    "            except Exception as e:\n",
    "                last_err = str(e)\n",
    "                print(f\"   ⚠️ Attempt {attempt}/{MAX_RETRIES} failed: {last_err}\")\n",
    "                if attempt < MAX_RETRIES:\n",
    "                    time.sleep(RETRY_DELAY_SEC)\n",
    "\n",
    "        if last_err:\n",
    "            run_summary[\"errors\"].append({\"symbol\": sym, \"error\": last_err})\n",
    "\n",
    "        time.sleep(SLEEP_BETWEEN_TICKERS_SEC)\n",
    "\n",
    "    # ---- Metrics from CSV (no Yahoo fundamentals) ----\n",
    "    try:\n",
    "        funds = fetch_metrics_from_csv(\n",
    "            FUND_TICKERS,\n",
    "            CSV_METRICS_PATH,\n",
    "            sector_map=SECTOR_MAP\n",
    "        )\n",
    "    except Exception as e:\n",
    "        funds = {sym: {\"error\": f\"CSV read failed: {e}\", \"sector\": SECTOR_MAP.get(sym)} for sym in FUND_TICKERS}\n",
    "\n",
    "    funds_run_path = os.path.join(run_dir, \"fundamentals.json\")\n",
    "    funds_cur_path = os.path.join(current_dir, \"fundamentals.json\")\n",
    "    write_json(funds_run_path, funds)\n",
    "    write_json(funds_cur_path, funds)\n",
    "\n",
    "    run_summary[\"fundamentals\"] = {\n",
    "        \"tickers\": FUND_TICKERS,\n",
    "        \"file_run\": funds_run_path,\n",
    "        \"file_current\": funds_cur_path,\n",
    "        \"source\": \"csv\",\n",
    "        \"csv_path\": CSV_METRICS_PATH,\n",
    "        \"fields\": [\"marketcap\", \"pb_current\", \"pb_current_pctile\", \"div_y\"]\n",
    "    }\n",
    "\n",
    "    # ---- Save summary ----\n",
    "    write_json(os.path.join(run_dir, \"summary.json\"), run_summary)\n",
    "    write_json(os.path.join(current_dir, \"summary.json\"), run_summary)\n",
    "\n",
    "    # ---- Auto-commit & push ----\n",
    "    git_commit_and_push(\n",
    "        repo_root=base_dir,\n",
    "        run_dir=run_dir,\n",
    "        current_dir=current_dir,\n",
    "        branch=\"main\"\n",
    "    )\n",
    "\n",
    "    print(\"🏁 Done.\")\n",
    "    if run_summary[\"errors\"]:\n",
    "        print(\"Some symbols failed (see summary.json).\")\n",
    "    else:\n",
    "        print(\"All symbols fetched successfully.\")\n",
    "    print(f\"Latest 'current' folder ready for Qualtrics: {current_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1675a264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Daily archive folder: /Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Programming/Git/pilot3-asset-data/runs/run_2025-08-19\n",
      "📂 Current folder for Qualtrics: /Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Programming/Git/pilot3-asset-data/current_day2\n",
      "⏳ Fetching 365-day data for BTC-USD…\n",
      " ✅ Wrote btc_365d.json (365 points)\n",
      "⏳ Fetching 365-day data for ETH-USD…\n",
      " ✅ Wrote eth_365d.json (365 points)\n",
      "⏳ Fetching 365-day data for XMR-USD…\n",
      " ✅ Wrote xmr_365d.json (365 points)\n",
      "⏳ Fetching 365-day data for APT21794-USD…\n",
      " ✅ Wrote apt21794_365d.json (365 points)\n",
      "⏳ Fetching 365-day data for QNT-USD…\n",
      " ✅ Wrote qnt_365d.json (365 points)\n",
      "⏳ Fetching 365-day data for TON11419-USD…\n",
      " ✅ Wrote ton11419_365d.json (365 points)\n",
      "⏳ Fetching 365-day data for DOT-USD…\n",
      " ✅ Wrote dot_365d.json (365 points)\n",
      "⏳ Fetching fundamentals for DOCN…\n",
      "⏳ Fetching fundamentals for MSFT…\n",
      "⏳ Fetching fundamentals for VZ…\n",
      "⏳ Fetching fundamentals for ZS…\n",
      "⏳ Fetching fundamentals for UFPI…\n",
      "⏳ Fetching fundamentals for DY…\n",
      "paul.grass@uni-bonn.de\n",
      "pagrass\n",
      "✅ Pushed to origin; GitHub Action will purge jsDelivr cache.\n",
      "🏁 Done.\n",
      "All symbols fetched successfully.\n",
      "Latest 'current' folder ready for Qualtrics: /Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Programming/Git/pilot3-asset-data/current_day2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To github.com:pagrass/pilot1-asset-data.git\n",
      "   79058b4..ba00fc3  main -> main\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import subprocess\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Deps: pip install yfinance curl_cffi\n",
    "from curl_cffi import requests\n",
    "import yfinance as yf\n",
    "\n",
    "# -------------------- Config --------------------\n",
    "\n",
    "# Stocks & cryptos\n",
    "STOCKS  = [\"CSCO\", \"TMUS\", \"TWLO\", \"PEGA\", \"ROG\", \"PD\"]\n",
    "\n",
    "#CRYPTOS = [\"BTC-USD\", \"ETH-USD\", \"XMR-USD\", \"APT21794-USD\", \"QNT-USD\", \"TON11419-USD\", \"DOT-USD\"]\n",
    "TICKERS = STOCKS \n",
    "#+ CRYPTOS\n",
    "\n",
    "FUND_TICKERS = [\"CSCO\", \"TMUS\", \"TWLO\", \"PEGA\", \"ROG\", \"PD\"]\n",
    "\n",
    "SECTOR_MAP = {\n",
    "    \"CSCO\": \"Information Technology\",\n",
    "    \"TMUS\": \"Communication Services\",\n",
    "    \"TWLO\": \"Information Technology\",\n",
    "    \"PEGA\": \"Information Technology\",\n",
    "    \"ROG\": \"Information Technology\",\n",
    "    \"PD\": \"Information Technologys\",\n",
    "}\n",
    "\n",
    "# Date window\n",
    "END   = datetime.now()\n",
    "START = END - timedelta(days=365)\n",
    "\n",
    "# Default base dir (each run gets a new subfolder here)\n",
    "DEFAULT_BASE_DIR = \"/Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Programming/Git/pilot4-asset-data\"\n",
    "\n",
    "\n",
    "# Rate limiting\n",
    "SLEEP_BETWEEN_TICKERS_SEC = 10\n",
    "MAX_RETRIES = 3\n",
    "RETRY_DELAY_SEC = 5\n",
    "\n",
    "# Safety: never allow writing into these substrings\n",
    "FORBIDDEN_SUBSTRINGS = [\"pilot3-asset-data\"]\n",
    "\n",
    "# -------------------- Helpers --------------------\n",
    "\n",
    "def git_commit_and_push(repo_root: str, run_dir: str, current_dir: str, branch: str = \"main\"):\n",
    "    # Only commit if there are changes in current/ or today's run folder\n",
    "    rel_run = os.path.relpath(run_dir, repo_root)\n",
    "    rel_cur = os.path.relpath(current_dir, repo_root)\n",
    "\n",
    "    # Make sure we're in the repo root so git paths work\n",
    "    cwd_before = os.getcwd()\n",
    "    os.chdir(repo_root)\n",
    "    try:\n",
    "        # Check if there are changes to these paths\n",
    "        diff = subprocess.run(\n",
    "            [\"git\", \"status\", \"--porcelain\", rel_cur, rel_run],\n",
    "            capture_output=True, text=True\n",
    "        )\n",
    "        if diff.returncode != 0:\n",
    "            print(\"⚠️  git status failed; not pushing.\")\n",
    "            return\n",
    "        if diff.stdout.strip() == \"\":\n",
    "            print(\"ℹ️  No changes to commit; skipping push.\")\n",
    "            return\n",
    "\n",
    "        # Ensure basic identity is set (won't override if already set)\n",
    "        subprocess.run([\"git\", \"config\", \"--get\", \"user.email\"], check=False)\n",
    "        subprocess.run([\"git\", \"config\", \"--get\", \"user.name\"], check=False)\n",
    "\n",
    "        # Stage just what we care about\n",
    "        subprocess.run([\"git\", \"add\", rel_cur, rel_run], check=True)\n",
    "\n",
    "        # Commit\n",
    "        msg = f\"Update data: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "        commit = subprocess.run([\"git\", \"commit\", \"-m\", msg], capture_output=True, text=True)\n",
    "        if commit.returncode != 0:\n",
    "            # Likely \"nothing to commit\" race; bail quietly\n",
    "            print(commit.stdout or commit.stderr or \"ℹ️  Nothing to commit.\")\n",
    "            return\n",
    "\n",
    "        # Push\n",
    "        subprocess.run([\"git\", \"push\", \"origin\", branch], check=True)\n",
    "        print(\"✅ Pushed to origin; GitHub Action will purge jsDelivr cache.\")\n",
    "    finally:\n",
    "        os.chdir(cwd_before)\n",
    "\n",
    "def fetch_fundamentals(symbols, yf_session, max_retries=3, retry_delay=5):\n",
    "    \"\"\"\n",
    "    Returns a dict {SYM: {eps, pe, div_y, sector}}.\n",
    "    Uses yfinance .info (can be slow/flaky; retried for robustness).\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    for sym in symbols:\n",
    "        print(f\"⏳ Fetching fundamentals for {sym}…\")\n",
    "        last_err = None\n",
    "        for attempt in range(1, max_retries + 1):\n",
    "            try:\n",
    "                t = yf.Ticker(sym, session=yf_session)\n",
    "                info = t.info  # may be slow / rate-limited\n",
    "                eps = info.get(\"trailingEps\")\n",
    "                price = info.get(\"regularMarketPrice\")\n",
    "                pe = round(price / eps, 1) if eps and price else None\n",
    "                dy = info.get(\"dividendYield\")\n",
    "                if dy is not None:\n",
    "                    dy = round(dy * 100, 1)\n",
    "                out[sym] = {\n",
    "                    \"eps\": eps,\n",
    "                    \"pe\": pe,\n",
    "                    \"div_y\": dy,\n",
    "                    \"sector\": SECTOR_MAP.get(sym),\n",
    "                }\n",
    "                last_err = None\n",
    "                break\n",
    "            except Exception as e:\n",
    "                last_err = str(e)\n",
    "                print(f\"   ⚠️  Attempt {attempt}/{max_retries} failed: {last_err}\")\n",
    "                if attempt < max_retries:\n",
    "                    time.sleep(retry_delay)\n",
    "        if last_err:\n",
    "            # record partial error so you see it in summary.json\n",
    "            out[sym] = {\"error\": last_err, \"sector\": SECTOR_MAP.get(sym)}\n",
    "        time.sleep(2)  # small spacing to be polite\n",
    "    return out\n",
    "\n",
    "\n",
    "def guard_path(path: str):\n",
    "    norm = os.path.normpath(path)\n",
    "    for bad in FORBIDDEN_SUBSTRINGS:\n",
    "        if bad in norm:\n",
    "            raise RuntimeError(f\"Refusing to write into forbidden path: {norm}\")\n",
    "\n",
    "def safe_mkdirs(path: str):\n",
    "    guard_path(path)\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "def make_daily_run_dir(base_dir: str) -> str:\n",
    "    date_str = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    run_dir = os.path.join(base_dir, \"runs\", f\"run_{date_str}\")\n",
    "    safe_mkdirs(run_dir)\n",
    "    return run_dir\n",
    "\n",
    "\n",
    "def ensure_current_dir(base_dir: str) -> str:\n",
    "    # Put current/ directly under base_dir (not inside runs/)\n",
    "    cur = os.path.join(base_dir, \"current_day2\")\n",
    "    safe_mkdirs(cur)\n",
    "    return cur\n",
    "\n",
    "def copy_to_current(src_path: str, current_dir: str):\n",
    "    guard_path(current_dir)\n",
    "    dst_path = os.path.join(current_dir, os.path.basename(src_path))\n",
    "    with open(src_path, \"rb\") as s, open(dst_path, \"wb\") as d:\n",
    "        d.write(s.read())\n",
    "    return dst_path\n",
    "\n",
    "\n",
    "\n",
    "def write_json(path: str, obj):\n",
    "    guard_path(path)\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(obj, f, indent=2)\n",
    "\n",
    "def create_or_update_symlink(target_dir: str, link_path: str):\n",
    "    # Create/refresh a 'latest' symlink for convenience (best-effort)\n",
    "    try:\n",
    "        if os.path.islink(link_path) or os.path.exists(link_path):\n",
    "            os.remove(link_path)\n",
    "        os.symlink(target_dir, link_path)\n",
    "    except Exception:\n",
    "        # Non-fatal if symlink fails (e.g., on certain filesystems)\n",
    "        pass\n",
    "\n",
    "# -------------------- Main --------------------\n",
    "\n",
    "def main():\n",
    "    session = requests.Session(impersonate=\"chrome124\")\n",
    "    yf_session = session  # yfinance accepts a curl_cffi session via 'session'\n",
    "\n",
    "    base_dir = os.getenv(\"DATA_BASE_DIR\", DEFAULT_BASE_DIR)\n",
    "    guard_path(base_dir)\n",
    "    safe_mkdirs(base_dir)\n",
    "\n",
    "    run_dir = make_daily_run_dir(base_dir)\n",
    "    current_dir = ensure_current_dir(base_dir)\n",
    "\n",
    "    print(f\"📁 Daily archive folder: {run_dir}\")\n",
    "    print(f\"📂 Current folder for Qualtrics: {current_dir}\")\n",
    "\n",
    "    run_summary = {\n",
    "        \"started_at\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "        \"window_start\": START.strftime(\"%Y-%m-%d\"),\n",
    "        \"window_end\": END.strftime(\"%Y-%m-%d\"),\n",
    "        \"files\": [],\n",
    "        \"errors\": [],\n",
    "    }\n",
    "\n",
    "    for sym in TICKERS:\n",
    "        print(f\"⏳ Fetching 365-day data for {sym}…\")\n",
    "        last_err = None\n",
    "        for attempt in range(1, MAX_RETRIES + 1):\n",
    "            try:\n",
    "                tkr = yf.Ticker(sym, session=yf_session)\n",
    "                df = tkr.history(\n",
    "                    start=START.strftime(\"%Y-%m-%d\"),\n",
    "                    end=END.strftime(\"%Y-%m-%d\"),\n",
    "                    auto_adjust=True,\n",
    "                )\n",
    "                if df is None or df.empty:\n",
    "                    raise ValueError(\"Empty dataframe returned.\")\n",
    "\n",
    "                pts = [\n",
    "                    [int(row_ts.timestamp() * 1000), round(float(row[\"Close\"]), 2)]\n",
    "                    for row_ts, row in df.iterrows()\n",
    "                    if row.get(\"Close\") is not None\n",
    "                ]\n",
    "                if not pts:\n",
    "                    raise ValueError(\"No valid close prices found.\")\n",
    "\n",
    "                out_sym = sym.replace(\"-USD\", \"\").replace(\".\", \"\").lower()\n",
    "\n",
    "                # Write to daily run folder\n",
    "                out_path = os.path.join(run_dir, f\"{out_sym}_365d.json\")\n",
    "                write_json(out_path, {\"prices\": pts})\n",
    "\n",
    "                # Also copy to current folder for Qualtrics\n",
    "                copy_to_current(out_path, current_dir)\n",
    "\n",
    "                print(f\" ✅ Wrote {out_sym}_365d.json ({len(pts)} points)\")\n",
    "\n",
    "                run_summary[\"files\"].append({\n",
    "                    \"symbol\": sym,\n",
    "                    \"file\": out_path,\n",
    "                    \"points\": len(pts),\n",
    "                    \"first_ts\": pts[0][0],\n",
    "                    \"last_ts\": pts[-1][0],\n",
    "                })\n",
    "                last_err = None\n",
    "                break\n",
    "            except Exception as e:\n",
    "                last_err = str(e)\n",
    "                print(f\"   ⚠️ Attempt {attempt}/{MAX_RETRIES} failed: {last_err}\")\n",
    "                if attempt < MAX_RETRIES:\n",
    "                    time.sleep(RETRY_DELAY_SEC)\n",
    "\n",
    "        if last_err:\n",
    "            run_summary[\"errors\"].append({\"symbol\": sym, \"error\": last_err})\n",
    "\n",
    "        time.sleep(SLEEP_BETWEEN_TICKERS_SEC)\n",
    "    # --- fundamentals ---\n",
    "    funds = fetch_fundamentals(FUND_TICKERS, yf_session, max_retries=MAX_RETRIES, retry_delay=RETRY_DELAY_SEC)\n",
    "\n",
    "    # save fundamentals.json in both places\n",
    "    funds_run_path = os.path.join(run_dir, \"fundamentals.json\")\n",
    "    funds_cur_path = os.path.join(current_dir, \"fundamentals.json\")\n",
    "    write_json(funds_run_path, funds)\n",
    "    write_json(funds_cur_path, funds)\n",
    "\n",
    "    # add to summary\n",
    "    run_summary[\"fundamentals\"] = {\n",
    "        \"tickers\": FUND_TICKERS,\n",
    "        \"file_run\": funds_run_path,\n",
    "        \"file_current\": funds_cur_path,\n",
    "    }\n",
    "\n",
    "    # Save summary to both locations\n",
    "    write_json(os.path.join(run_dir, \"summary.json\"), run_summary)\n",
    "    write_json(os.path.join(current_dir, \"summary.json\"), run_summary)\n",
    "\n",
    "    # Auto-commit & push (triggers purge workflow)\n",
    "    git_commit_and_push(\n",
    "        repo_root=base_dir,\n",
    "        run_dir=run_dir,\n",
    "        current_dir=current_dir,\n",
    "        branch=\"main\"\n",
    "    )\n",
    "\n",
    "\n",
    "    print(\"🏁 Done.\")\n",
    "    if run_summary[\"errors\"]:\n",
    "        print(\"Some symbols failed (see summary.json).\")\n",
    "    else:\n",
    "        print(\"All symbols fetched successfully.\")\n",
    "    print(f\"Latest 'current' folder ready for Qualtrics: {current_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb8d686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Daily archive folder: /Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Programming/Git/pilot3-asset-data/runs/run_2025-10-20\n",
      "📂 Current folder for Qualtrics: /Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Programming/Git/pilot3-asset-data/current_day2\n",
      "⏳ Fetching 365-day data for CSCO…\n",
      " ✅ Wrote csco_365d.json (249 points)\n",
      "⏳ Fetching 365-day data for MSFT…\n",
      " ✅ Wrote msft_365d.json (249 points)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 293\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLatest \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrent\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m folder ready for Qualtrics: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 293\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[1], line 255\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m last_err:\n\u001b[1;32m    253\u001b[0m         run_summary[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrors\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msymbol\u001b[39m\u001b[38;5;124m\"\u001b[39m: sym, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m: last_err})\n\u001b[0;32m--> 255\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(SLEEP_BETWEEN_TICKERS_SEC)\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# --- fundamentals ---\u001b[39;00m\n\u001b[1;32m    257\u001b[0m funds \u001b[38;5;241m=\u001b[39m fetch_fundamentals(FUND_TICKERS, yf_session, max_retries\u001b[38;5;241m=\u001b[39mMAX_RETRIES, retry_delay\u001b[38;5;241m=\u001b[39mRETRY_DELAY_SEC)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import subprocess\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Deps: pip install yfinance curl_cffi\n",
    "from curl_cffi import requests\n",
    "import yfinance as yf\n",
    "\n",
    "# -------------------- Config --------------------\n",
    "\n",
    "# Stocks & cryptos\n",
    "STOCKS  = [\"CSCO\", \"ARLO\", \"CMPO\", \"ZS\", \"KO\", \"MCD\"]\n",
    "#STOCKS  = []\n",
    "\n",
    "#CRYPTOS = [\"BTC-USD\", \"ETH-USD\", \"XMR-USD\", \"APT21794-USD\", \"QNT-USD\", \"TON11419-USD\", \"DOT-USD\"]\n",
    "CRYPTOS = []\n",
    "TICKERS = STOCKS + CRYPTOS\n",
    "\n",
    "FUND_TICKERS = [\"DOCN\", \"ARLO\", \"CMPO\", \"ZS\", \"KO\", \"MCD\"]\n",
    "\n",
    "SECTOR_MAP = {\n",
    "    \"DOCN\": \"Technology\",\n",
    "    \"MSFT\": \"Technology\",\n",
    "    \"VZ\":  \"Communication Services\",\n",
    "    \"ZS\":  \"Technology\",\n",
    "    \"UFPI\": \"Basic Materials\",\n",
    "    \"DY\":   \"Industrials\",\n",
    "}\n",
    "\n",
    "# Date window\n",
    "END   = datetime.now()\n",
    "START = END - timedelta(days=365)\n",
    "\n",
    "# Default base dir (each run gets a new subfolder here)\n",
    "DEFAULT_BASE_DIR = \"/Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Programming/Git/pilot3-asset-data\"\n",
    "\n",
    "\n",
    "# Rate limiting\n",
    "SLEEP_BETWEEN_TICKERS_SEC = 10\n",
    "MAX_RETRIES = 3\n",
    "RETRY_DELAY_SEC = 5\n",
    "\n",
    "# Safety: never allow writing into these substrings\n",
    "FORBIDDEN_SUBSTRINGS = [\"pilot2-asset-data\"]\n",
    "\n",
    "# -------------------- Helpers --------------------\n",
    "\n",
    "def git_commit_and_push(repo_root: str, run_dir: str, current_dir: str, branch: str = \"main\"):\n",
    "    # Only commit if there are changes in current/ or today's run folder\n",
    "    rel_run = os.path.relpath(run_dir, repo_root)\n",
    "    rel_cur = os.path.relpath(current_dir, repo_root)\n",
    "\n",
    "    # Make sure we're in the repo root so git paths work\n",
    "    cwd_before = os.getcwd()\n",
    "    os.chdir(repo_root)\n",
    "    try:\n",
    "        # Check if there are changes to these paths\n",
    "        diff = subprocess.run(\n",
    "            [\"git\", \"status\", \"--porcelain\", rel_cur, rel_run],\n",
    "            capture_output=True, text=True\n",
    "        )\n",
    "        if diff.returncode != 0:\n",
    "            print(\"⚠️  git status failed; not pushing.\")\n",
    "            return\n",
    "        if diff.stdout.strip() == \"\":\n",
    "            print(\"ℹ️  No changes to commit; skipping push.\")\n",
    "            return\n",
    "\n",
    "        # Ensure basic identity is set (won't override if already set)\n",
    "        subprocess.run([\"git\", \"config\", \"--get\", \"user.email\"], check=False)\n",
    "        subprocess.run([\"git\", \"config\", \"--get\", \"user.name\"], check=False)\n",
    "\n",
    "        # Stage just what we care about\n",
    "        subprocess.run([\"git\", \"add\", rel_cur, rel_run], check=True)\n",
    "\n",
    "        # Commit\n",
    "        msg = f\"Update data: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "        commit = subprocess.run([\"git\", \"commit\", \"-m\", msg], capture_output=True, text=True)\n",
    "        if commit.returncode != 0:\n",
    "            # Likely \"nothing to commit\" race; bail quietly\n",
    "            print(commit.stdout or commit.stderr or \"ℹ️  Nothing to commit.\")\n",
    "            return\n",
    "\n",
    "        # Push\n",
    "        subprocess.run([\"git\", \"push\", \"origin\", branch], check=True)\n",
    "        print(\"✅ Pushed to origin; GitHub Action will purge jsDelivr cache.\")\n",
    "    finally:\n",
    "        os.chdir(cwd_before)\n",
    "\n",
    "def fetch_fundamentals(symbols, yf_session, max_retries=3, retry_delay=5):\n",
    "    \"\"\"\n",
    "    Returns a dict {SYM: {eps, pe, div_y, sector}}.\n",
    "    Uses yfinance .info (can be slow/flaky; retried for robustness).\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    for sym in symbols:\n",
    "        print(f\"⏳ Fetching fundamentals for {sym}…\")\n",
    "        last_err = None\n",
    "        for attempt in range(1, max_retries + 1):\n",
    "            try:\n",
    "                t = yf.Ticker(sym, session=yf_session)\n",
    "                info = t.info  # may be slow / rate-limited\n",
    "                eps = info.get(\"trailingEps\")\n",
    "                price = info.get(\"regularMarketPrice\")\n",
    "                pe = round(price / eps, 1) if eps and price else None\n",
    "                dy = info.get(\"dividendYield\")\n",
    "                if dy is not None:\n",
    "                    dy = round(dy * 100, 1)\n",
    "                out[sym] = {\n",
    "                    \"eps\": eps,\n",
    "                    \"pe\": pe,\n",
    "                    \"div_y\": dy,\n",
    "                    \"sector\": SECTOR_MAP.get(sym),\n",
    "                }\n",
    "                last_err = None\n",
    "                break\n",
    "            except Exception as e:\n",
    "                last_err = str(e)\n",
    "                print(f\"   ⚠️  Attempt {attempt}/{max_retries} failed: {last_err}\")\n",
    "                if attempt < max_retries:\n",
    "                    time.sleep(retry_delay)\n",
    "        if last_err:\n",
    "            # record partial error so you see it in summary.json\n",
    "            out[sym] = {\"error\": last_err, \"sector\": SECTOR_MAP.get(sym)}\n",
    "        time.sleep(2)  # small spacing to be polite\n",
    "    return out\n",
    "\n",
    "\n",
    "def guard_path(path: str):\n",
    "    norm = os.path.normpath(path)\n",
    "    for bad in FORBIDDEN_SUBSTRINGS:\n",
    "        if bad in norm:\n",
    "            raise RuntimeError(f\"Refusing to write into forbidden path: {norm}\")\n",
    "\n",
    "def safe_mkdirs(path: str):\n",
    "    guard_path(path)\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "def make_daily_run_dir(base_dir: str) -> str:\n",
    "    date_str = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    run_dir = os.path.join(base_dir, \"runs\", f\"run_{date_str}\")\n",
    "    safe_mkdirs(run_dir)\n",
    "    return run_dir\n",
    "\n",
    "\n",
    "def ensure_current_dir(base_dir: str) -> str:\n",
    "    # Put current/ directly under base_dir (not inside runs/)\n",
    "    cur = os.path.join(base_dir, \"current_day2\")\n",
    "    safe_mkdirs(cur)\n",
    "    return cur\n",
    "\n",
    "def copy_to_current(src_path: str, current_dir: str):\n",
    "    guard_path(current_dir)\n",
    "    dst_path = os.path.join(current_dir, os.path.basename(src_path))\n",
    "    with open(src_path, \"rb\") as s, open(dst_path, \"wb\") as d:\n",
    "        d.write(s.read())\n",
    "    return dst_path\n",
    "\n",
    "\n",
    "\n",
    "def write_json(path: str, obj):\n",
    "    guard_path(path)\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(obj, f, indent=2)\n",
    "\n",
    "def create_or_update_symlink(target_dir: str, link_path: str):\n",
    "    # Create/refresh a 'latest' symlink for convenience (best-effort)\n",
    "    try:\n",
    "        if os.path.islink(link_path) or os.path.exists(link_path):\n",
    "            os.remove(link_path)\n",
    "        os.symlink(target_dir, link_path)\n",
    "    except Exception:\n",
    "        # Non-fatal if symlink fails (e.g., on certain filesystems)\n",
    "        pass\n",
    "\n",
    "# -------------------- Main --------------------\n",
    "\n",
    "def main():\n",
    "    session = requests.Session(impersonate=\"chrome124\")\n",
    "    yf_session = session  # yfinance accepts a curl_cffi session via 'session'\n",
    "\n",
    "    base_dir = os.getenv(\"DATA_BASE_DIR\", DEFAULT_BASE_DIR)\n",
    "    guard_path(base_dir)\n",
    "    safe_mkdirs(base_dir)\n",
    "\n",
    "    run_dir = make_daily_run_dir(base_dir)\n",
    "    current_dir = ensure_current_dir(base_dir)\n",
    "\n",
    "    print(f\"📁 Daily archive folder: {run_dir}\")\n",
    "    print(f\"📂 Current folder for Qualtrics: {current_dir}\")\n",
    "\n",
    "    run_summary = {\n",
    "        \"started_at\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "        \"window_start\": START.strftime(\"%Y-%m-%d\"),\n",
    "        \"window_end\": END.strftime(\"%Y-%m-%d\"),\n",
    "        \"files\": [],\n",
    "        \"errors\": [],\n",
    "    }\n",
    "\n",
    "    for sym in TICKERS:\n",
    "        print(f\"⏳ Fetching 365-day data for {sym}…\")\n",
    "        last_err = None\n",
    "        for attempt in range(1, MAX_RETRIES + 1):\n",
    "            try:\n",
    "                tkr = yf.Ticker(sym, session=yf_session)\n",
    "                df = tkr.history(\n",
    "                    start=START.strftime(\"%Y-%m-%d\"),\n",
    "                    end=END.strftime(\"%Y-%m-%d\"),\n",
    "                    auto_adjust=True,\n",
    "                )\n",
    "                if df is None or df.empty:\n",
    "                    raise ValueError(\"Empty dataframe returned.\")\n",
    "\n",
    "                pts = [\n",
    "                    [int(row_ts.timestamp() * 1000), round(float(row[\"Close\"]), 2)]\n",
    "                    for row_ts, row in df.iterrows()\n",
    "                    if row.get(\"Close\") is not None\n",
    "                ]\n",
    "                if not pts:\n",
    "                    raise ValueError(\"No valid close prices found.\")\n",
    "\n",
    "                out_sym = sym.replace(\"-USD\", \"\").replace(\".\", \"\").lower()\n",
    "\n",
    "                # Write to daily run folder\n",
    "                out_path = os.path.join(run_dir, f\"{out_sym}_365d.json\")\n",
    "                write_json(out_path, {\"prices\": pts})\n",
    "\n",
    "                # Also copy to current folder for Qualtrics\n",
    "                copy_to_current(out_path, current_dir)\n",
    "\n",
    "                print(f\" ✅ Wrote {out_sym}_365d.json ({len(pts)} points)\")\n",
    "\n",
    "                run_summary[\"files\"].append({\n",
    "                    \"symbol\": sym,\n",
    "                    \"file\": out_path,\n",
    "                    \"points\": len(pts),\n",
    "                    \"first_ts\": pts[0][0],\n",
    "                    \"last_ts\": pts[-1][0],\n",
    "                })\n",
    "                last_err = None\n",
    "                break\n",
    "            except Exception as e:\n",
    "                last_err = str(e)\n",
    "                print(f\"   ⚠️ Attempt {attempt}/{MAX_RETRIES} failed: {last_err}\")\n",
    "                if attempt < MAX_RETRIES:\n",
    "                    time.sleep(RETRY_DELAY_SEC)\n",
    "\n",
    "        if last_err:\n",
    "            run_summary[\"errors\"].append({\"symbol\": sym, \"error\": last_err})\n",
    "\n",
    "        time.sleep(SLEEP_BETWEEN_TICKERS_SEC)\n",
    "    # --- fundamentals ---\n",
    "    funds = fetch_fundamentals(FUND_TICKERS, yf_session, max_retries=MAX_RETRIES, retry_delay=RETRY_DELAY_SEC)\n",
    "\n",
    "    # save fundamentals.json in both places\n",
    "    funds_run_path = os.path.join(run_dir, \"fundamentals.json\")\n",
    "    funds_cur_path = os.path.join(current_dir, \"fundamentals.json\")\n",
    "    write_json(funds_run_path, funds)\n",
    "    write_json(funds_cur_path, funds)\n",
    "\n",
    "    # add to summary\n",
    "    run_summary[\"fundamentals\"] = {\n",
    "        \"tickers\": FUND_TICKERS,\n",
    "        \"file_run\": funds_run_path,\n",
    "        \"file_current\": funds_cur_path,\n",
    "    }\n",
    "\n",
    "    # Save summary to both locations\n",
    "    write_json(os.path.join(run_dir, \"summary.json\"), run_summary)\n",
    "    write_json(os.path.join(current_dir, \"summary.json\"), run_summary)\n",
    "\n",
    "    # Auto-commit & push (triggers purge workflow)\n",
    "    git_commit_and_push(\n",
    "        repo_root=base_dir,\n",
    "        run_dir=run_dir,\n",
    "        current_dir=current_dir,\n",
    "        branch=\"main\"\n",
    "    )\n",
    "\n",
    "\n",
    "    print(\"🏁 Done.\")\n",
    "    if run_summary[\"errors\"]:\n",
    "        print(\"Some symbols failed (see summary.json).\")\n",
    "    else:\n",
    "        print(\"All symbols fetched successfully.\")\n",
    "    print(f\"Latest 'current' folder ready for Qualtrics: {current_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
