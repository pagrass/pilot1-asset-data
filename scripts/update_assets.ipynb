{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1675a264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Daily archive folder: /Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Programming/Git/pilot3-asset-data/runs/run_2025-08-10\n",
      "üìÇ Current folder for Qualtrics: /Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Programming/Git/pilot3-asset-data/current\n",
      "‚è≥ Fetching 365-day data for NVDA‚Ä¶\n",
      " ‚úÖ Wrote nvda_365d.json (249 points)\n",
      "‚è≥ Fetching 365-day data for TER‚Ä¶\n",
      " ‚úÖ Wrote ter_365d.json (249 points)\n",
      "‚è≥ Fetching 365-day data for PAYC‚Ä¶\n",
      " ‚úÖ Wrote payc_365d.json (249 points)\n",
      "‚è≥ Fetching 365-day data for KO‚Ä¶\n",
      " ‚úÖ Wrote ko_365d.json (249 points)\n",
      "‚è≥ Fetching 365-day data for PEP‚Ä¶\n",
      " ‚úÖ Wrote pep_365d.json (249 points)\n",
      "‚è≥ Fetching 365-day data for BTC-USD‚Ä¶\n",
      " ‚úÖ Wrote btc_365d.json (364 points)\n",
      "‚è≥ Fetching 365-day data for ETH-USD‚Ä¶\n",
      " ‚úÖ Wrote eth_365d.json (364 points)\n",
      "‚è≥ Fetching 365-day data for ADA-USD‚Ä¶\n",
      " ‚úÖ Wrote ada_365d.json (364 points)\n",
      "‚è≥ Fetching 365-day data for ATOM-USD‚Ä¶\n",
      " ‚úÖ Wrote atom_365d.json (364 points)\n",
      "‚è≥ Fetching 365-day data for QNT-USD‚Ä¶\n",
      " ‚úÖ Wrote qnt_365d.json (364 points)\n",
      "‚è≥ Fetching 365-day data for LTC-USD‚Ä¶\n",
      " ‚úÖ Wrote ltc_365d.json (364 points)\n",
      "‚è≥ Fetching 365-day data for TON11419-USD‚Ä¶\n",
      " ‚úÖ Wrote ton11419_365d.json (364 points)\n",
      "‚è≥ Fetching fundamentals for NVDA‚Ä¶\n",
      "‚è≥ Fetching fundamentals for PAYC‚Ä¶\n",
      "‚è≥ Fetching fundamentals for TER‚Ä¶\n",
      "‚è≥ Fetching fundamentals for TGT‚Ä¶\n",
      "‚è≥ Fetching fundamentals for COST‚Ä¶\n",
      "‚è≥ Fetching fundamentals for KO‚Ä¶\n",
      "‚è≥ Fetching fundamentals for PEP‚Ä¶\n",
      "paul.grass@uni-bonn.de\n",
      "pagrass\n",
      "‚úÖ Pushed to origin; GitHub Action will purge jsDelivr cache.\n",
      "üèÅ Done.\n",
      "All symbols fetched successfully.\n",
      "Latest 'current' folder ready for Qualtrics: /Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Programming/Git/pilot3-asset-data/current\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To github.com:pagrass/pilot1-asset-data.git\n",
      "   0c793f0..45eb83c  main -> main\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import subprocess\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Deps: pip install yfinance curl_cffi\n",
    "from curl_cffi import requests\n",
    "import yfinance as yf\n",
    "\n",
    "# -------------------- Config --------------------\n",
    "\n",
    "# Stocks & cryptos\n",
    "STOCKS  = [\"NVDA\", \"TER\", \"PAYC\", \"KO\", \"PEP\"]\n",
    "CRYPTOS = [\"BTC-USD\", \"ETH-USD\", \"ADA-USD\", \"ATOM-USD\", \"QNT-USD\", \"LTC-USD\", \"TON11419-USD\"]\n",
    "TICKERS = STOCKS + CRYPTOS\n",
    "\n",
    "FUND_TICKERS = [\"NVDA\", \"PAYC\", \"TER\", \"TGT\", \"COST\", \"KO\", \"PEP\"]\n",
    "\n",
    "SECTOR_MAP = {\n",
    "    \"NVDA\": \"Technology\",\n",
    "    \"PAYC\": \"Technology\",\n",
    "    \"TER\":  \"Technology\",\n",
    "    \"TGT\":  \"Consumer Defensive\",\n",
    "    \"COST\": \"Consumer Defensive\",\n",
    "    \"KO\":   \"Consumer Defensive\",\n",
    "    \"PEP\":  \"Consumer Defensive\",\n",
    "}\n",
    "\n",
    "# Date window\n",
    "END   = datetime.now()\n",
    "START = END - timedelta(days=365)\n",
    "\n",
    "# Default base dir (each run gets a new subfolder here)\n",
    "DEFAULT_BASE_DIR = \"/Users/paulgrass/Library/Mobile Documents/com~apple~CloudDocs/Documents/Programming/Git/pilot3-asset-data\"\n",
    "\n",
    "\n",
    "# Rate limiting\n",
    "SLEEP_BETWEEN_TICKERS_SEC = 10\n",
    "MAX_RETRIES = 3\n",
    "RETRY_DELAY_SEC = 5\n",
    "\n",
    "# Safety: never allow writing into these substrings\n",
    "FORBIDDEN_SUBSTRINGS = [\"pilot2-asset-data\"]\n",
    "\n",
    "# -------------------- Helpers --------------------\n",
    "\n",
    "def git_commit_and_push(repo_root: str, run_dir: str, current_dir: str, branch: str = \"main\"):\n",
    "    # Only commit if there are changes in current/ or today's run folder\n",
    "    rel_run = os.path.relpath(run_dir, repo_root)\n",
    "    rel_cur = os.path.relpath(current_dir, repo_root)\n",
    "\n",
    "    # Make sure we're in the repo root so git paths work\n",
    "    cwd_before = os.getcwd()\n",
    "    os.chdir(repo_root)\n",
    "    try:\n",
    "        # Check if there are changes to these paths\n",
    "        diff = subprocess.run(\n",
    "            [\"git\", \"status\", \"--porcelain\", rel_cur, rel_run],\n",
    "            capture_output=True, text=True\n",
    "        )\n",
    "        if diff.returncode != 0:\n",
    "            print(\"‚ö†Ô∏è  git status failed; not pushing.\")\n",
    "            return\n",
    "        if diff.stdout.strip() == \"\":\n",
    "            print(\"‚ÑπÔ∏è  No changes to commit; skipping push.\")\n",
    "            return\n",
    "\n",
    "        # Ensure basic identity is set (won't override if already set)\n",
    "        subprocess.run([\"git\", \"config\", \"--get\", \"user.email\"], check=False)\n",
    "        subprocess.run([\"git\", \"config\", \"--get\", \"user.name\"], check=False)\n",
    "\n",
    "        # Stage just what we care about\n",
    "        subprocess.run([\"git\", \"add\", rel_cur, rel_run], check=True)\n",
    "\n",
    "        # Commit\n",
    "        msg = f\"Update data: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "        commit = subprocess.run([\"git\", \"commit\", \"-m\", msg], capture_output=True, text=True)\n",
    "        if commit.returncode != 0:\n",
    "            # Likely \"nothing to commit\" race; bail quietly\n",
    "            print(commit.stdout or commit.stderr or \"‚ÑπÔ∏è  Nothing to commit.\")\n",
    "            return\n",
    "\n",
    "        # Push\n",
    "        subprocess.run([\"git\", \"push\", \"origin\", branch], check=True)\n",
    "        print(\"‚úÖ Pushed to origin; GitHub Action will purge jsDelivr cache.\")\n",
    "    finally:\n",
    "        os.chdir(cwd_before)\n",
    "\n",
    "def fetch_fundamentals(symbols, yf_session, max_retries=3, retry_delay=5):\n",
    "    \"\"\"\n",
    "    Returns a dict {SYM: {eps, pe, div_y, sector}}.\n",
    "    Uses yfinance .info (can be slow/flaky; retried for robustness).\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    for sym in symbols:\n",
    "        print(f\"‚è≥ Fetching fundamentals for {sym}‚Ä¶\")\n",
    "        last_err = None\n",
    "        for attempt in range(1, max_retries + 1):\n",
    "            try:\n",
    "                t = yf.Ticker(sym, session=yf_session)\n",
    "                info = t.info  # may be slow / rate-limited\n",
    "                eps = info.get(\"trailingEps\")\n",
    "                price = info.get(\"regularMarketPrice\")\n",
    "                pe = round(price / eps, 1) if eps and price else None\n",
    "                dy = info.get(\"dividendYield\")\n",
    "                if dy is not None:\n",
    "                    dy = round(dy * 100, 1)\n",
    "                out[sym] = {\n",
    "                    \"eps\": eps,\n",
    "                    \"pe\": pe,\n",
    "                    \"div_y\": dy,\n",
    "                    \"sector\": SECTOR_MAP.get(sym),\n",
    "                }\n",
    "                last_err = None\n",
    "                break\n",
    "            except Exception as e:\n",
    "                last_err = str(e)\n",
    "                print(f\"   ‚ö†Ô∏è  Attempt {attempt}/{max_retries} failed: {last_err}\")\n",
    "                if attempt < max_retries:\n",
    "                    time.sleep(retry_delay)\n",
    "        if last_err:\n",
    "            # record partial error so you see it in summary.json\n",
    "            out[sym] = {\"error\": last_err, \"sector\": SECTOR_MAP.get(sym)}\n",
    "        time.sleep(2)  # small spacing to be polite\n",
    "    return out\n",
    "\n",
    "\n",
    "def guard_path(path: str):\n",
    "    norm = os.path.normpath(path)\n",
    "    for bad in FORBIDDEN_SUBSTRINGS:\n",
    "        if bad in norm:\n",
    "            raise RuntimeError(f\"Refusing to write into forbidden path: {norm}\")\n",
    "\n",
    "def safe_mkdirs(path: str):\n",
    "    guard_path(path)\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "def make_daily_run_dir(base_dir: str) -> str:\n",
    "    date_str = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    run_dir = os.path.join(base_dir, \"runs\", f\"run_{date_str}\")\n",
    "    safe_mkdirs(run_dir)\n",
    "    return run_dir\n",
    "\n",
    "\n",
    "def ensure_current_dir(base_dir: str) -> str:\n",
    "    # Put current/ directly under base_dir (not inside runs/)\n",
    "    cur = os.path.join(base_dir, \"current\")\n",
    "    safe_mkdirs(cur)\n",
    "    return cur\n",
    "\n",
    "def copy_to_current(src_path: str, current_dir: str):\n",
    "    guard_path(current_dir)\n",
    "    dst_path = os.path.join(current_dir, os.path.basename(src_path))\n",
    "    with open(src_path, \"rb\") as s, open(dst_path, \"wb\") as d:\n",
    "        d.write(s.read())\n",
    "    return dst_path\n",
    "\n",
    "\n",
    "\n",
    "def write_json(path: str, obj):\n",
    "    guard_path(path)\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(obj, f, indent=2)\n",
    "\n",
    "def create_or_update_symlink(target_dir: str, link_path: str):\n",
    "    # Create/refresh a 'latest' symlink for convenience (best-effort)\n",
    "    try:\n",
    "        if os.path.islink(link_path) or os.path.exists(link_path):\n",
    "            os.remove(link_path)\n",
    "        os.symlink(target_dir, link_path)\n",
    "    except Exception:\n",
    "        # Non-fatal if symlink fails (e.g., on certain filesystems)\n",
    "        pass\n",
    "\n",
    "# -------------------- Main --------------------\n",
    "\n",
    "def main():\n",
    "    session = requests.Session(impersonate=\"chrome124\")\n",
    "    yf_session = session  # yfinance accepts a curl_cffi session via 'session'\n",
    "\n",
    "    base_dir = os.getenv(\"DATA_BASE_DIR\", DEFAULT_BASE_DIR)\n",
    "    guard_path(base_dir)\n",
    "    safe_mkdirs(base_dir)\n",
    "\n",
    "    run_dir = make_daily_run_dir(base_dir)\n",
    "    current_dir = ensure_current_dir(base_dir)\n",
    "\n",
    "    print(f\"üìÅ Daily archive folder: {run_dir}\")\n",
    "    print(f\"üìÇ Current folder for Qualtrics: {current_dir}\")\n",
    "\n",
    "    run_summary = {\n",
    "        \"started_at\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "        \"window_start\": START.strftime(\"%Y-%m-%d\"),\n",
    "        \"window_end\": END.strftime(\"%Y-%m-%d\"),\n",
    "        \"files\": [],\n",
    "        \"errors\": [],\n",
    "    }\n",
    "\n",
    "    for sym in TICKERS:\n",
    "        print(f\"‚è≥ Fetching 365-day data for {sym}‚Ä¶\")\n",
    "        last_err = None\n",
    "        for attempt in range(1, MAX_RETRIES + 1):\n",
    "            try:\n",
    "                tkr = yf.Ticker(sym, session=yf_session)\n",
    "                df = tkr.history(\n",
    "                    start=START.strftime(\"%Y-%m-%d\"),\n",
    "                    end=END.strftime(\"%Y-%m-%d\"),\n",
    "                    auto_adjust=True,\n",
    "                )\n",
    "                if df is None or df.empty:\n",
    "                    raise ValueError(\"Empty dataframe returned.\")\n",
    "\n",
    "                pts = [\n",
    "                    [int(row_ts.timestamp() * 1000), round(float(row[\"Close\"]), 2)]\n",
    "                    for row_ts, row in df.iterrows()\n",
    "                    if row.get(\"Close\") is not None\n",
    "                ]\n",
    "                if not pts:\n",
    "                    raise ValueError(\"No valid close prices found.\")\n",
    "\n",
    "                out_sym = sym.replace(\"-USD\", \"\").replace(\".\", \"\").lower()\n",
    "\n",
    "                # Write to daily run folder\n",
    "                out_path = os.path.join(run_dir, f\"{out_sym}_365d.json\")\n",
    "                write_json(out_path, {\"prices\": pts})\n",
    "\n",
    "                # Also copy to current folder for Qualtrics\n",
    "                copy_to_current(out_path, current_dir)\n",
    "\n",
    "                print(f\" ‚úÖ Wrote {out_sym}_365d.json ({len(pts)} points)\")\n",
    "\n",
    "                run_summary[\"files\"].append({\n",
    "                    \"symbol\": sym,\n",
    "                    \"file\": out_path,\n",
    "                    \"points\": len(pts),\n",
    "                    \"first_ts\": pts[0][0],\n",
    "                    \"last_ts\": pts[-1][0],\n",
    "                })\n",
    "                last_err = None\n",
    "                break\n",
    "            except Exception as e:\n",
    "                last_err = str(e)\n",
    "                print(f\"   ‚ö†Ô∏è Attempt {attempt}/{MAX_RETRIES} failed: {last_err}\")\n",
    "                if attempt < MAX_RETRIES:\n",
    "                    time.sleep(RETRY_DELAY_SEC)\n",
    "\n",
    "        if last_err:\n",
    "            run_summary[\"errors\"].append({\"symbol\": sym, \"error\": last_err})\n",
    "\n",
    "        time.sleep(SLEEP_BETWEEN_TICKERS_SEC)\n",
    "    # --- fundamentals ---\n",
    "    funds = fetch_fundamentals(FUND_TICKERS, yf_session, max_retries=MAX_RETRIES, retry_delay=RETRY_DELAY_SEC)\n",
    "\n",
    "    # save fundamentals.json in both places\n",
    "    funds_run_path = os.path.join(run_dir, \"fundamentals.json\")\n",
    "    funds_cur_path = os.path.join(current_dir, \"fundamentals.json\")\n",
    "    write_json(funds_run_path, funds)\n",
    "    write_json(funds_cur_path, funds)\n",
    "\n",
    "    # add to summary\n",
    "    run_summary[\"fundamentals\"] = {\n",
    "        \"tickers\": FUND_TICKERS,\n",
    "        \"file_run\": funds_run_path,\n",
    "        \"file_current\": funds_cur_path,\n",
    "    }\n",
    "\n",
    "    # Save summary to both locations\n",
    "    write_json(os.path.join(run_dir, \"summary.json\"), run_summary)\n",
    "    write_json(os.path.join(current_dir, \"summary.json\"), run_summary)\n",
    "\n",
    "    # Auto-commit & push (triggers purge workflow)\n",
    "    git_commit_and_push(\n",
    "        repo_root=base_dir,\n",
    "        run_dir=run_dir,\n",
    "        current_dir=current_dir,\n",
    "        branch=\"main\"\n",
    "    )\n",
    "\n",
    "\n",
    "    print(\"üèÅ Done.\")\n",
    "    if run_summary[\"errors\"]:\n",
    "        print(\"Some symbols failed (see summary.json).\")\n",
    "    else:\n",
    "        print(\"All symbols fetched successfully.\")\n",
    "    print(f\"Latest 'current' folder ready for Qualtrics: {current_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
